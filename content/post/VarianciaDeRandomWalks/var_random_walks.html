---
title: "Comportamento de Random Walks"
author: "Pedro Cavalcante"
date: '2019-06-10'
output:
  html_document:
    df_print: paged
  pdf_document: default
katex: yes
categories:
- R
- Econometria
- Estatística
slug: var-random-walks
tags:
  - Econometria
  - OLS
  - Simulações
authors: ["pedrocava"]
draft: FALSE
---



<p>Um processo estocástico autoregressivo com <span class="math inline">\(1\)</span> lag, doravante chamado de AR1, é, no caso simplificado em uma dimensão que eu abordarei aqui, descrito como:</p>
<p><span class="math display">\[y_t = \beta y_{t-1} + \mu_t\]</span> Para algum <span class="math inline">\(y_o = c\)</span> e, no caso com que lidaremos hoje, <span class="math inline">\(\beta \in \mathbb{R}\)</span> e <span class="math inline">\(\mu_t \sim N(0, \sigma^2)\)</span>, logo vale que $[_t] = 0 $.</p>
<div id="variancia-e-esperanca-do-processo-ar1" class="section level1">
<h1>Variância e Esperança do Processo AR1</h1>
<div id="esperanca" class="section level2">
<h2>Esperança</h2>
<p>Vamos agora caracterizar o Valor Esperado e a Variância desse processo, assim como caracterizaríamos os dois primeiros momentos centrais de uma distribuição. Note que o operador de Esperança é <em>linear</em>, isso é importante.</p>
<p><span class="math display">\[\mathbb{E} [y_t] = \mathbb{E} [\beta y_{t-1} + \mu_t]\]</span> <span class="math display">\[\mathbb{E} [y_t] = \beta\mathbb{E} [ y_{t-1}] + \mathbb{E}[\mu_t]\]</span> <span class="math display">\[\mathbb{E} [y_t] = \beta\mathbb{E} [ \beta y_{t-2} + \mu_{t-1}] + 0\]</span> <span class="math display">\[\mathbb{E} [y_t] = \beta^2\mathbb{E} [y_{t-2}] + \mathbb{E}[\mu_{t-1}] + 0\]</span></p>
<p>Acho que o leitor já captou o padrão aqui. Se não, recomendo continuar o processo mais algumas vezes no papel. No final chegaremos em:</p>
<p><span class="math display">\[\mathbb{E} [y_t] = \beta^t y_0\]</span></p>
<p>Espero que seja claro ao leitor também - ou que a verificação não tome muito tempo - que se <span class="math inline">\(| \beta | &lt; 1\)</span> então <span class="math inline">\(\lim_{t \to \infty}\beta^t y_0 = 0\)</span>. No entanto o mesmo limite explode para infinito se o parâmetro for maior ou igual a <span class="math inline">\(1\)</span> em módulo.</p>
</div>
<div id="variancia" class="section level2">
<h2>Variância</h2>
<p>Note que variância de constantes dadas é <span class="math inline">\(0\)</span> e que variância de combinações lineares de variáveis aleatórias independentes é soma das variâncias de cada variável. Podemos reduzir a variância de <span class="math inline">\(y_t\)</span> à:</p>
<p><span class="math display">\[\mathbb{V}[y_t] = \mathbb{V} [\sum_{i=1}^t \mu_i] \]</span> <span class="math display">\[ \mathbb{V} [\sum_{i=1}^t \mu_i]  = \sum_{i=1}^t\mathbb{V}[\mu_i]\]</span> Como <span class="math inline">\(\mathbb{V}[\mu_i] = \sigma^2\)</span>, vale que <span class="math inline">\(\mathbb{V}[y_t] = t \sigma^2\)</span>. Esperamos variância crescente com o tempo, porém que sorteios diferentes do mesmo processo se cancelem perto de zero - ou melhor, que não exista alguma forte de viés para números positivos ou negativos. Será que podemos verificar isso acontecendo?</p>
</div>
</div>
<div id="simulando" class="section level1">
<h1>Simulando</h1>
<p>Vamos simular alguns processos random walk:</p>
<pre class="r"><code>library(tidyverse)
library(gganimate)

processos = list()
tmax = 10000
inicial = 0
nprocessos = 50
beta = 1
set.seed(1234)

for(i in 1:nprocessos) {
  
  t = seq(1, tmax)
  processo = vector(length = tmax)
  processo[1] = inicial
  
  for(j in 2:tmax) {
  
  choque = rnorm(n = 1)
    
  processo[j] = beta*processo[j-1] + choque
  
  }
  
  dados = tibble(t = t,
                 processo = processo)

  
  processos[[i]] = dados

  
}

processos = do.call(rbind, processos) # agregamos as listas</code></pre>
<p>Vamos entender o que acabamos de produzir. Criamos <code>50</code> processos estocásticos com características muito similares. Condição inicial no zero, sujeitos a choques com a mesma distribuição probabilística e com a mesma “inércia”. Valores anteriores são repassados integralmente. Vamos primeiro visualizar um processo sozinho:</p>
<pre class="r"><code>processos[1:tmax,] %&gt;%
  ggplot(aes(x = t, y = processo)) +
  geom_point() +
  transition_reveal(t)</code></pre>
<p><img src="/post/var_random_walks_files/figure-html/unnamed-chunk-2-1.gif" /><!-- --></p>
<pre class="r"><code>processos[1:tmax,] %&gt;%
  ggplot(aes(x = t, y = processo)) +
  geom_line(size = 1.2)</code></pre>
<p><img src="/post/var_random_walks_files/figure-html/unnamed-chunk-2-2.png" width="1400" /></p>
<p>Vamos observar agora o comportamento conjunto dos processos <em>pontualmente</em> em cada instante <span class="math inline">\(t\)</span>.</p>
<pre class="r"><code>processos %&gt;%
  ggplot(aes(x = t, y = processo)) +
  geom_point() +
  transition_reveal(t)</code></pre>
<p><img src="/post/var_random_walks_files/figure-html/unnamed-chunk-3-1.gif" /><!-- --></p>
<pre class="r"><code>processos %&gt;%
  ggplot(aes(x = t, y = processo)) +
  geom_point() </code></pre>
<p><img src="/post/var_random_walks_files/figure-html/unnamed-chunk-4-1.png" width="1400" /></p>
<p>De fato, parece que conseguimos o</p>
<p>bservar o comportamento previsto na teoria. Em breve revisitarei esse post falando de processos AR1 que regridem assintoticamente a um patamar e mostrar como isso está conectado com o Teorema do Ponto Fixo de Banach - de que já falei aqui no blog.</p>
</div>
