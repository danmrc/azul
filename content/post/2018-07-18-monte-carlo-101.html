---
title: Monte Carlo 101
author: Daniel Coutinho
date: '2018-07-18'
slug: monte-carlo-101
categories:
  - R
  - Tutorial
tags:
  - Simulação
  - Monte Carlo
  - Tutoriais
authors: []
---



<p>Simulações são uma excelente maneira de entender um novo conceito, bem como explorar propriedades de estimadores. Quando queremos entender as propriedades não assintóticas dos estimadores, são raros os casos em que temos soluções analíticas: mínimos quadrados é um dos casos, que parcialmente justifica a popularidade do método. Em muitos casos, usamos simulações para entender as características de um estimador em amostras finitas. Esse post tenta prover uma ilustração de como criar simulações e usa-las. Nos próximos posts, irei usar simulações frequentemente.</p>
<p>Simulações, no nosso contexto, dependem de repetir a mesma operação várias vezes: fazemos vários sorteios de variáveis aleatórias no computador e usamos essas variáveis para testar ou ilustrar ou entender ou medir alguma coisa. A descrição anterior é vaga porque o método é muito amplo: podemos testar coisas relativamente triviais - por exemplo, que MQO é realmente não viesado - até medir as características de estimadores de ponta: a quantidade de artigos publicados que contam com uma seção de experimento Monte Carlo é notável.</p>
<p>Uma boa pergunta é por que isso deveria funcionar? Isso é, como de fato nós sabemos que, fazendo alguns milhares de simulações obtemos um resultado final interessante? A ideia é intuitiva: o que aconteceria se eu pegasse um milhão de bases de dados e aplicasse esse método proposto para estimar o parâmetro de um modelo? A justificativa mais formal é incrivelmente simples: a lei dos grandes números. Sabemos que, sobre condições bem gerais, para a variável aleatória <span class="math inline">\(x\)</span> com média <span class="math inline">\(\mu\)</span>:</p>
<p><span class="math display">\[plim_{n \rightarrow \infty} \bar{X} = \mu\]</span></p>
<p>Onde <span class="math inline">\(\bar{X}\)</span> é a média amostral e <span class="math inline">\(plim\)</span> é o limite em probabilidade. Então se repetirmos o mesmo experimento milhares de vezes (e, apesar de não ser infinito, milhares de vezes tende a ser o suficiente), devemos recuperar o valor aproximado do paramêtro de interesse.</p>
<p>Aqui vai um passo a passo de como fazer simulações:</p>
<ul>
<li><p>Temos que criar um objeto que vai receber as estimativas. Este objeto pode ser de diferentes formatos dependendo do que nós queremos: um vetor se é um único paramêtro, uma matriz se são vários vetores, ou até mesmo uma lista!</p></li>
<li><p>Escrever um for ou while para repetir a mesma tarefa milhares de vezes</p></li>
<li><p>Dentro do for (ou while), a operação que queremos repetir alguns milhares de vezes</p></li>
<li><p>Alguma maneira de vizualizar o que nós estimamos</p></li>
</ul>
<div id="um-exemplo" class="section level1">
<h1>Um exemplo</h1>
<p>Vamos fazer a seguinte simulação, que exemplifica a ideia geral: será que o estimador de MQO é realmente não viesado? Sabemos que sim - basta consultar qualquer livro de econometria - mas vamos proceder para ver quão poderosa é o método. Eu vou sortear os números de uma distribuição normal usando o comando <code>rnorm</code>, mas isso não é estritamente necessário. Eis o código:</p>
<pre class="r"><code>set.seed(985)

bet &lt;- rep(0,1000) #Vetor cheio de zeros para ser preenchido com as estimativas

for(i in 1:1000){
  x &lt;- rnorm(100)
  y &lt;- 2+x+rnorm(100)
  modelo &lt;- lm(y ~ x)
  bet[i] &lt;- coef(modelo)[2]
}

mean(bet)</code></pre>
<pre><code>## [1] 1.00705</code></pre>
<p>Veja que a média foi bem próxima do valor verdadeiro do parâmetro, mesmo com uma amostra relativamente pequena. Vamos levar isso além: vamos escrever uma função que nos permite alterar o tamanho da amostra do problema e vamos ver como a coisa evolui para cada tamanho de amostra:</p>
<pre class="r"><code>library(knitr)

simu &lt;- function(n, k =1000){ # n é o tamanho da amostra e k é o número de replicações
  bet &lt;- rep(0,k) #Vetor cheio de zeros para ser preenchido com as estimativas

  for(i in 1:k){
    x &lt;- rnorm(n)
    y &lt;- 2+x+rnorm(n)
    modelo &lt;- lm(y ~ x)
    bet[i] &lt;- coef(modelo)[2]
  }
  return(bet)
}

n0 &lt;- simu(10)
n1 &lt;- simu(25)
n2 &lt;- simu(50)
n3 &lt;- simu(100)
n4 &lt;- simu(125)
n5 &lt;- simu(150)

medias &lt;- c(mean(n0),mean(n1),mean(n2),mean(n3),mean(n4),mean(n5))
dp &lt;- c(sd(n0),sd(n1),sd(n2),sd(n3),sd(n4),sd(n5)) #por que não computar o erro padrão também?

tabela &lt;- rbind(medias,dp)
rownames(tabela) &lt;- c(&quot;Média&quot;, &quot;Desvio Padrão&quot;)
colnames(tabela) &lt;- c(&quot;n = 10&quot;,&quot;n = 25&quot;,&quot;n = 50&quot;,&quot;n = 100&quot;,&quot;n = 125&quot;,&quot;n = 150&quot;)

kable(tabela,caption = &quot;Viés do estimador de MQO com diferentes tamanhos de amostra (n). Valor verdadeiro = 1&quot;)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-2">Table 1: </span>Viés do estimador de MQO com diferentes tamanhos de amostra (n). Valor verdadeiro = 1</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">n = 10</th>
<th align="right">n = 25</th>
<th align="right">n = 50</th>
<th align="right">n = 100</th>
<th align="right">n = 125</th>
<th align="right">n = 150</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Média</td>
<td align="right">1.0067587</td>
<td align="right">0.9905194</td>
<td align="right">1.0021588</td>
<td align="right">1.0014421</td>
<td align="right">0.9999834</td>
<td align="right">1.0049840</td>
</tr>
<tr class="even">
<td>Desvio Padrão</td>
<td align="right">0.3805114</td>
<td align="right">0.2085449</td>
<td align="right">0.1430919</td>
<td align="right">0.0995256</td>
<td align="right">0.0888961</td>
<td align="right">0.0853065</td>
</tr>
</tbody>
</table>
<p>Veja que, na tabela acima, o desvio padrão é o desvio padrão “verdadeiro”, i.e., calculado usando os betas estimados na simulação. Veja que a estimativa do erro padrão dada pelo R não deve ser muito fora deste valor.</p>
<p>Essa foi uma rápida introdução a como fazer simulações usando o R. Obviamente, é possível fazer simulações muito mais complicadas. Mas a ideia está bem representada no exemplo acima. Nos próximos posts, eu irei usar simulações para explorar propriedades de estimadores e ilustrar vários conceitos (não só em estatística).</p>
</div>
