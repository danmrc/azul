---
title: "Classificando cursos no ProUni com Random Forest"
author: "Pedro Cavalcante"
date: '2019-05-07'
output:
  html_document:
    self_contained: FALSE
draft: FALSE
katex: TRUE
categories:
- R
- Economia da Educação
- Machine Learning
slug: prouni-rf-classificacao
tags:
- Random Forest
- Cross Validation
authors: ["pedrocava"]
---



<p>Meu primeiro post aqui no blog foi um exercício de classificação. Como, com clustering <span class="math inline">\(k\)</span>-means, poderíamos classificar cursos no ProUni? Aqui eu vou responder a mesma pergunta com uma ferramenta diferente, Random Forests. Vou explicar breve e simplesmente o que são/ como funcionam e depois estimar tudo.</p>
<p>Já aviso de antemão que a explicaçõe será muito superficial. É um assunto razoavelmente complicado então prefiro assim porque posso (i) evitar erros, (ii) não assustar alguns leitores e (iii) pular para a parte que mais me interessa que é a mão na massa. Também não vou falar em decisão dos hiperparâmetros do modelo, porque acho que esse assunto merece um post próprio.</p>
<div id="arvore-de-decisao" class="section level1">
<h1>Árvore de Decisão</h1>
<p>Quem já estudou teoria dos jogos e conhece a notação em árvore de um jogo sequencial vai estar razoavelmente familiarizado com essa apresentação. Quem já teve algum contato com teoria dos grafos e estudou Árvores também deve conhecer isso de alguma maneira.</p>
<p>Cada vértice representa um teste lógico que retorna algo como verdadeiro/falso, maior/menor/igual ou algum tipo de controle de fluxo. É um objeto bem flexível, útil tanto para criar algum esquema de decisão quanto classificar observações. Treinar uma árvore de decisão é essencialmente testar regras, heurísticas.</p>
<div class="figure">
<img src="https://cdn-images-1.medium.com/max/1200/0*Yclq0kqMAwCQcIV_.jpg" alt="“Exemplo de Árvore de Decisão”" />
<p class="caption">“Exemplo de Árvore de Decisão”</p>
</div>
<p>O que uma Random Forest faz é treinar <em>várias</em> árvores de decisão diferentes com subconjuntos aleatórios das variáveis explicativas. Tendo várias árvores de decisão treinadas em subconjuntos aleatórios, a <em>floresta</em> resultante devolve uma ponderação dos vários resultados. Isso abre novas fronteiras de flexbilidade e capa sutilezas e não-linearidades nos dados que <span class="math inline">\(k\)</span>-means e probits não captariam. Mais ainda, permite avaliar a <em>importância</em> das variáveis explicativas com noções diferentes de significância estatística. Basta avaliar em quantos nodos que usam uma certa explicativa reduzem o erro da floresta.</p>
<p>O artigo seminal, com uma exposição mais detalhada é <a href="https://www.stat.berkeley.edu/~breiman/randomforest2001.pdf">Breiman (2001)</a>.</p>
</div>
<div id="rodando-random-forests" class="section level1">
<h1>Rodando Random Forests</h1>
<p>Agora que vamos à prática, aviso logo que vou omitir a análise exploratória dos dados. Já fiz isso aqui no <a href="https://azul.netlify.com/2018/08/11/prouni-clustering/">primeiro post em que usei esses dados</a>. Vamos usar o pacote <code>randomForest</code>, que implementa os algoritmos de Breiman em R, para estimar nossas árvores, selecionar variáveis e fazer validação cruzada - um procedimento muito bem explicado <a href="https://azul.netlify.com/2019/04/20/cross-validation/">neste post do Daniel</a>. Vou definir a semente <span class="math inline">\(1234\)</span> que uso sempre. Prometo em outro post falar de sementes aleatórias, escolha e manipulação delas. Se você não é familiarizao com definição de sementes, não se preocupe, não vai fazer falta.</p>
<pre class="r"><code>library(randomForest)
library(tictoc)
set.seed(1234)

head(prouni)</code></pre>
<pre><code>##   mensalidade     medicina   nota vagas uf
## 1     9999.99     Medicina 740.22    29 MS
## 2     9836.40 Não-Medicina 663.36     1 CE
## 3     9715.61     Medicina 739.62    23 SP
## 4     9689.34 Não-Medicina 651.00     5 CE
## 5     9674.34     Medicina 758.32    12 AC
## 6     9650.00     Medicina 738.92    23 SP
##                                         uni
## 1         Universidade Anhanguera - UNIDERP
## 2         Faculdade Princesa do Oeste - FPO
## 3 Universidade Cidade de São Paulo - UNICID
## 4         Faculdade Princesa do Oeste - FPO
## 5       Faculdade Barão do Rio Branco - FAB
## 6  Universidade do Oeste Paulista - UNOESTE
##                                                                     campus
## 1                                       CAMPO GRANDE - SEDE - Miguel Couto
## 2                                               UNIDADE SEDE - São Vicente
## 3               UNIVERSIDADE CIDADE DE SÃO PAULO - UNICID - SEDE - Tatuapé
## 4                                               UNIDADE SEDE - São Vicente
## 5               CAMPUS  - RIO BRANCO - JARDIM EUROPA II - Jardim Europa II
## 6 CAMPUS I  SEDE ADMINISTRATIVA PRESIDENTE PRUDENTE - Cidade Universitária
##        curso
## 1   Medicina
## 2 Enfermagem
## 3   Medicina
## 4 Psicologia
## 5   Medicina
## 6   Medicina</code></pre>
<p>Como queremos classificar cursos entre Medicina, explicativas não incluirão campus nem nome do curso. Tirei o nome do curso em particular porque a implementação do <code>randomForest</code> não lida com preditores categóricos com mais de 53 níveis e temos aproximadamente 215 cursos diferentes na base.</p>
<p>Vamos agora rodar repetidas vezes o modelo em um subconjutno aleatório dos dados, que chamaremos de <em>in-sample</em> e com o modelo treinado testaremos a performance dele classificando o outro subconjunto dos dados, que chamaremos de <em>out-of-sample</em>. É sempre importante fazer esse tipo de teste para se proteger de overfitting e ter uma ideia da precisão do seu modelo.</p>
<pre class="r"><code>n = 100 # número de validações
resultadosRF = vector()

tic(&quot;Estimando&quot;)
for(i in 1:n) {
  
set.seed(i) # usamos sementes variadas para escolher subconjuntos diferentes dos dados
  
prouni$index = sample(2, 
                     nrow(prouni), 
                     replace = TRUE,
                     prob = c(0.5, 0.5)) # atribuímos às observações um status de grupo 1 ou 2

sample = prouni[prouni$index == 1,] # grupo 1 será o grupo in-sample
out.sample = prouni[prouni$index == 2,] # grupo 2 será o out-of-sample

floresta = randomForest(medicina ~ mensalidade + nota + vagas + uf,
                        data = sample, 
                        importance = TRUE) # estimamos a floresta

out.sample$predicaoRF = predict(floresta, 
                                out.sample,
                                type = &quot;response&quot;) # com a floresta estimada prevemos o curso

resultRF = as.vector(table(out.sample$medicina, out.sample$predicaoRF))
resultadosRF[i] = resultRF[1]/(resultRF[1] + resultRF[2]) # uma espécie de taxa de acerto
}
toc()</code></pre>
<pre><code>## Estimando: 286.571 sec elapsed</code></pre>
<pre class="r"><code>floresta #sumário da última floresta estimada</code></pre>
<pre><code>## 
## Call:
##  randomForest(formula = medicina ~ mensalidade + nota + vagas +      uf, data = sample, importance = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 0.01%
## Confusion matrix:
##              Medicina Não-Medicina  class.error
## Medicina           59            0 0.000000e+00
## Não-Medicina        1        16131 6.198859e-05</code></pre>
<pre class="r"><code>mean(resultadosRF) # taxa média de acerto</code></pre>
<pre><code>## [1] 0.9909667</code></pre>
<p>Também podemos avaliar a importância das variáveis usando <code>randomForest::importance()</code> ou visualizar isso com <code>randomForest::varImpPlot()</code>. A métrica específica é diminuição média da acurácia classificatória da floresta.</p>
<pre class="r"><code>varImpPlot(floresta) </code></pre>
<p><img src="/post/prouni-random-forest-svm/prouni_rf_svm_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<pre class="r"><code>importance(floresta, 
           type = 1,
           scale = TRUE)</code></pre>
<pre><code>##             MeanDecreaseAccuracy
## mensalidade             45.92490
## nota                    40.08904
## vagas                   11.26562
## uf                       4.72057</code></pre>
<p>Eu juro que tentei achar maneiras claras e diretas de interpretar a importância das variáveis de uma Random Forest, mas pelo visto isso <em>não</em> existe. Achei alguns comentários legais sobre assunto <a href="https://stats.stackexchange.com/questions/197827/how-to-interpret-mean-decrease-in-accuracy-and-mean-decrease-gini-in-random-fore">nese post do CrossValidated</a> e aparentemente a melhor ideia é ler como utilidade, ordinalmente.</p>
</div>
