---
title: 'Amostrando de distribuições difíceis: o Markov Chain Monte Carlo'
author: Daniel Coutinho
date: '2020-01-16'
slug: markov-chain-monte-carlo
categories:
  - R
  - Econometria
tags:
  - Monte Carlo
  - Markov Chain Monte Carlo
  - Bayesiana
draft: true
---

Eu recentemente tive a chance de brincar com o Markov Chain Monte Carlo (MCMC daqui por diante) no contexto de DSGE - e quando eu digo brincar eu não quero dizer que usei o Dynare, por sinal. O algoritmo é bastante esperto e funciona surpreendentemente bem. Eu não vou me atrever a entrar nos detalhes de _porque_ funciona, mas eu vou descrever o algoritmo com algum detalhe e mostrar um exemplozinhho de regressão Bayesiana. 

O algoritmo tem várias etapas e vai requerer que a gente tenha uma (a) distribuição alvo e (b) um _kernel_. A ideia é que é difícil retirar números aleatórios da distribuição alvo e nós queremos obter esses números por algum motivo. No caso bayesiano, eles querem obter a distribuição do parâmetro dada a regra de Bayes. Vamos temporariamente fingir que somos bayesianos. Seja $x$ os dados e $\theta$ os parâmetros, portanto queremos a _posterior_:

$$p(\theta|x) = \frac{p(\theta)\ell(x|\theta)}{p(x)}$$

Onde $p(\theta)$ é a _prior_ do parâmetro - a distribuição que específica a crença do pesquisador antes de ver os dados - $\ell(x|\theta)$ é a verossimelhança e $p(x)$ é a distribuição de x. Veja que os dois primeiros elementos são fáceis de especificar; $p(x)$ requer a distribuição de x marginalizando para o parâmetro, o que pode ser impossível de obter - se temos dez parâmetros isso requer dez integrais e nós passamos a conhecer a maldição da dimensionalidade. 

Existem vários algoritmos que fazem isso, e eu vou discutir um deles neste post. Mas todos basicamente partem da mesma ideia: sorteie números aleatórios de alguma distribuição que a gente sabe sortear. Use a densidade da distribuição que queremos de fato obter uma amostra para decidir se o parâmetro sorteado deve ser aceito ou não. Se quisermos uma estatística específica da distribuição - média, moda, mediana, desvio padrão - basta calcular a estatística empírica a partir da amostra e deixar a Lei dos Grandes Números agir. 

A primeira sacada esperta é notar que, dado duas propostas de parâmetros, $\theta$ e $\theta^{\prime}$, $p(\theta|x)/p(\theta^\prime|x)$ cancela o $p(x)$. Assim, se conseguirmos uma maneira de amostrar a distribuição usando a razão, nos livramos da integral. 

A segunda sacada é notar que, já que estamos usando uma razão, podemos usar o fato que se migrarmos de um ponto de menor probabilidade na _posterior_ para um de maior probabilidade, então a razão será maior que 1. 

A terceira sacada é que se a gente rejeitar toda vez que a _posterior_ diminuir, nós teremos dois problemas:

1. Naturalmente o algoritmo vai convergir para o máximo e ficar preso lá

2. Pior, ele pode convergir para um máximo local e ficar preso lá. 

Para entender o segundo ponto, dê uma olhada na seguinte função:

```{r}
xx <- seq(-2,2,by = 0.05)
yy <- dnorm(xx,mean = -1,sd = 0.7) + dnorm(xx,mean=1, sd = 0.5)

plot(xx,yy, type = "l", 
     xlab = " ", 
     ylab = " ")

dm1 <- dnorm(-1, mean = -1, sd = 0.7)
d1 <- dnorm(1, mean = 1, sd = 0.5)
d0 <- dnorm(0,mean = 1, sd = 0.5) + dnorm(0, mean = -1, sd = 0.7) 

points(-1, dm1, pch = 17, col = 2, cex = 2)
points(1, d1, pch = 17,col = 4, cex = 2)
points(0, d0, pch = 17,col = 3, cex = 2)

arrows(x0 = -1, y0 = dm1, x1 = 0, y1 = d0, lty = 2, lwd = 2)
arrows(x0 = 0, y0 = d0, x1 = 1, y1 = d1, lty = 2, lwd = 2)
```

Se começamos no triângulo vermelho, qualquer ponto ao redor reduz a densidade. Mas veja que o triângulo vermelho é um máximo local e o triângulo azul o máximo global. Nós potencialmente gostaríamos de aceitar até mesmo o ponto verde se nós fizermos o caminho indicado pelas setas. Obviamente, dificilmente teremos uma situação tão evidente como essa, mas é bastante ilustrativo. 

Então nós não queremos rejeitar um ponto potencial só porque ele reduz a _posterior_ - queremos aceitar ele, de vez em quando. A ideia aqui é aceitar ele com maior probabilidade quanto mais próxima de 1 for a razão $p(\theta^\prime|x)/p(\theta|x)$. 

Espero ter convencido o leitor que é útil trabalhar com a razão $p(\theta^\prime|x)/p(\theta|x)$ para _aceitar ou rejeitar_ um valor como representativo da distribuição. Mas ainda não atacamos sobre o problema fundamental de _como_ escolher esse valor. O procedimento é bem simples: escolha a distribuição _kernel_ e sorteie um valor dela. Esse vai ser o valor que a ser testado.

A distribuição _kernel_ tem que ser espertamente escolhida, porque existem várias condições sobre o _kernel_ para garantir que a distribuição do algoritmo é a distribuição alvo. Para todos os efeitos, a normal centrada no último valor aceito é perfeito para os própositos - a escolha da variância é muito importante e eu vou discutir abaixo. Usar a distribuição centrada no último valor aceito gera o algoritmo chamado _Random Walk Metropolis Hasting_ - a parte do Random Walk se deve ao fato da distribuição do sorteio ser centrado no último valor aceito. 

Nós também vamos querer corrigir a probabilidade de aceitação e rejeição pelo _kernel_. A intuição é que não só importa o quão provável é o novo parâmetro dado a posterior, mas o quão provável é o parâmetro dado o _kernel_: se nós sorteamos um parâmetro na ponta do kernel isso tem que ser levado em conta. Uma explicação um pouco mais séria: o importante é que a probabilidade de passar do ponto x para o ponto y seja igual. Uma distribuição qualquer não garante isso, mas corrigir a razão pelo kernel faz com que isso seja satisfeito. Então, seja $\mathcal{K}(\theta^\prime|\theta)$ a probabilidade de passar do ponto $\theta$ para $\theta^\prime$. A razão que vamos nos preocupar é:

$$\frac{p(\theta|x)\mathcal{K}(\theta^\prime|\theta)}{p(\theta^\prime|x)\mathcal{K}(\theta|\theta^\prime)}$$

Veja que se o kernel faz com que a probabilidade de passar do ponto x para o ponto y é igual a de passar do ponto y para o ponto x, então $\mathcal{K}(\theta^\prime|\theta)$ = $\mathcal{K}(\theta|\theta^\prime)$, os termos se cancelam e voltamos a nossa razão que eu coloquei no começo.

Eu escrevi bastante coisa e parece justo fazer um resumo do passo a passo do discutido até aqui:

Defina a função _kernel_, a _posterior_ (que depende da verossimelhança e das _priors_) e um ponto inicial do espaço paramétrico, $\theta$

1. Sorteie um possível valor possível do parâmetro da distribuição _kernel_. Chame esse valor de $\theta^\prime$
2. Compute $r = \max \left(1,\frac{p(\theta|x)\mathcal{K}(\theta^\prime|\theta)}{p(\theta^\prime|x)\mathcal{K}(\theta|\theta^\prime)}\right)$
3. Sorteie u ~ Uniforme(0,1)
4. Se $r > u$, aceite e $\theta = \theta^\prime$. Caso contrário, rejeite e $\theta = \theta$
5. Itere n vezes

Veja que se o parâmetro for rejeitado, _o valor antigo vai ser repetido_ na base. Isso vai garantir com que pontos de alta probabilidade apareçam mais na distribuição empírica. 

# Um exemplo

Como de praxe, um exemplo vai ajudar muito a entender tudo que eu escrevi. Vamos fazer uma situação super simples onde eu tenho uma regressão $y = \beta{}x + \varepsilon$ e $\beta = 1,5$, 100 observações e $\varepsilon \sim N(0,1)$

```{r}

x <- rnorm(100)
y <- 1.5*x + rnorm(100)
```

Vamos fazer a função de verossimelhança. Como o erro é normal, então $y|x \sim N(\beta{}x,1)$. Eu vou escrever direto a _log_ verossimelhança

```{r}
loglike <- function(y,x,beta){
  sum(log(dnorm(y-beta*x)))
}
```

Para a prior, eu vou colocar uma Normal de média 0 e desvio padrão 3, e com isso temos a posterior:

```{r}
posterior <- function(y,x,beta){
  loglike(y,x,beta) + log(dnorm(beta,mean=0,sd=3))
}
```

Note que como eu estou trabalhando com o log de tudo, ao invés de multiplicar a verossimelhança pela prior, eu somo as duas. 

Agora sim podemos passar para o MCMC