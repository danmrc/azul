---
title: Usando clustering para identificar cursos no Prouni
author: Pedro Cavalcante
date: '2018-08-09'
slug: prouni-clustering
categories:
  - R
  - Clustering
  - Economia
tags:
  - Economia da Educação
  - R
  - Clustering
authors: []
---

```{r echo=FALSE}
##### Carregar bibliotecas

library(dplyr)
library(ggplot2)
library(readxl)
library(dbscan)
library(mclust)
library(cluster)
library(scales)

##### A base de dados pode ser encontrada aqui: https://github.com/danmrc/azul/tree/master/content/post/ProUni

prouni <- read_excel("C:\Users\pedro\Google Drive\Dados\Próprios\prouni.xlsx", 
                     sheet = "Formatados_para_rodar")

##### Aqui selecionamos as variáveis de interesse: 
##### Dummy de Medicina
##### Mensalidade
##### Nota de Corte

coercivo <- data.frame(prouni$mensalidade, 
                        prouni$Medicina, 
                          prouni$nota_integral_ampla)
##### Inspecione a base
summary(coercivo)

##### Algoritimos de clustering não lidam bem com NAs
##### Iremos retirar obs que não sejam completas

final$label <- ifelse(final$prouni.Medicina == 1, "Medicina", "Não-Medicina")
coercivo$dropador <- complete.cases(coercivo)
final <- coercivo[coercivo$dropador == TRUE,]

##### Agora retiramos o vetor residual que indica se a obs é completa
final$dropador <- NULL
```


Você provavelmente conhece alguém que se formou no ensino médio e foi fazer um infame _cursinho_ pensando em uma aprovação numa graduação em Medicina. Pois é esperado, são cursos estranhamente competitivos e com as - de longe - maiores notas de corte. Por serem tão anômalos, podem ser um exercício interessante de classificação.

Vou expor brevemente a matemática por trás do processo de _Clustering k-means_, alguns problemas que surgem na hora de aplicar o algoritimo e aplica-lo em uma questão interessante de economia da educação, _carrer choice_. 

## O que é clustering?

Clustering é uma classe de algoritimos não-supervisionados para classificação de observações. Existem vários tipos, cores e tamanho de técnicas de clustering, mas essa bonita variedade vai ficar para outro dia porque o foco de hoje é a abordagem de distância centrada.

!["Agrupamento de observações"](https://i.imgur.com/S65Sk9c.jpg)

A visualização é razoavelmente clara, clusters são literalmente agrupamentos. Com base em alguns critérios dependentes do algoritimo a ser utilizado, você classifica uma observação em um _ou_ outro agrupamento (exceto nos modelos _fuzzy_, mas isso fica para outro dia).


## Clustering k-means como um problema de otimização

Um problema de otimização irrestrita tem, a grosso modo, dois _features_. A *função objetivo* a ser maximizada ou minimizada e o *instrumento* com o qual atingir tal objetivo. Aqueles familiarizados com o canônico método de estimação por Mínimos Quadrados Ordinários vão reconhecer alguma semelheança. 

K-means, ao invés de minimizar quadrado dos resíduos, minimiza a soma do quadrado da distância dentro do cluster (WCSS, em inglês). Nossos instrumentos são $k$, o número de agrupamentos e $S_i$, os conjuntos que dão qual elemento está em qual agrupamento. Podem parecer instrumentos redundantes à primeira vista. Pense que para um mesmo número de agrupamentos, é possível ter combinações de conjuntos com WCSSs diferentes.

Algumas definições antes. $k$ é o número de clusters, $S_i$ é conjunto de elementos do i-ésimo cluster, $\mu_i$ é a média do i-ésimo cluster.

$$ \text{arg min}_S \sum_{i=1}^k \sum_{x_j \in S_i} || x_j - \mu_i ||^2 $$

O leitor atento percebeu que $k$ não aparece aqui como um instrumento do problema, mas sim como um parâmetro dado. Bem, aí está uma das peculiaridades de k-means, _nós escolhemos o k_. É uma tarefa que tem um pouco de ciência e muita arte, vou me aprofundar um pouco nela mais à frente.

## Os dados

A amostra que temos é do ProUni de 2017 e conta com algo em torno de 32 mil observações. Já tive o trabalho de limpar a base para vossa apreciação e vou deixa-la disponível [aqui](https://github.com/danmrc/azul/tree/master/content/post/ProUni) e o código que contém tudo [aqui](https://github.com/danmrc/azul/blob/master/content/post/ProUni/prouni_cluster.R). Vamos primeiro explorar nossa amostra com a ajuda do ````ggplot2````.

```{r}
final %>%
  ggplot(aes(x=prouni.mensalidade, y=prouni.nota_integral_ampla,
             colour = prouni.Medicina, show.legend = FALSE)) +
  geom_point()+
  stat_density_2d()+
  xlab("Mensalidade do curso no ProUni")+
  ylab("Nota de Corte do curso no ProUni")
````

![Mapa de densidade de notas de corte, mensalidades. Observações em azul mais claro são de Medicina.](https://i.imgur.com/i5yfR5V.png)

```{r}
final %>%
ggplot(aes(x=prouni.mensalidade)) + 
  xlim(0,2500) +
  geom_histogram(aes(y=..density..), binwidth = 50) +
  xlab("Mensalidade do curso no ProUni") + 
  ylab("") +
  geom_density(colour =" medium blue", size = 1.5) +
  scale_y_continuous(labels = percent) +
  geom_vline(aes(xintercept=mean(prouni.mensalidade, na.rm=T)),   
             color="black", linetype="dashed", size=1)
             
 ````

!["Histograma das Mensalidades"](https://i.imgur.com/twn7b7n.png)

```{r}
final %>%
  ggplot(aes(x=prouni.mensalidade)) + 
  xlab("Mensalidade do curso no ProUni") + 
  ylab("") +
  geom_histogram(aes(y=..density..), binwidth = 300) +
  scale_y_continuous(labels = percent) +
  facet_wrap(~label) +
  geom_density(colour =" medium blue", size = 1)
````

!["Histograma das Mensalidades diferenciando cursos de Medicina"](https://i.imgur.com/14R87DN.png)

Os próximos dois gráficos tem códigos análogos aos dois anteriores e estão disponíveis no script. 

Aqui observamos três coisas muito interessantes. A primeira é que notas de corte seguem muito bem uma distribuição normal _exceto_ pela regra que impõe nota de corte mínima de 450 no ProUni e Sisu. É o tipo de coisa em que seria legal aplicar um [Teste de Densidade de McCrary (2006)](https://eml.berkeley.edu/~jmccrary/mccrary2006_DCdensity.pdf). Depois, que Medicina tem um padrão de distribuição de notas bem diferente do resto.

![Histograma das notas de corte](https://i.imgur.com/sipwjrG.png)

![Histograma das notas de corte diferenciando Medicina](https://i.imgur.com/VjfJH7K.png)

## Como escolher k?

Essa é a pergunta de um milhão de dólares, honestamente. Eu encontrei dois principais métodos, um é computacionalmente exigente e preciso, o outro é computacionalmente simples e depende mais de interpretação. 

A primeira e mais complicada é a _Gap Statistic_ ([Tbishirani, Walther e Hastie, 2001](https://statweb.stanford.edu/~gwalther/gap)). O método envolve algumas computações com bootstrap, então exige uma máquina preparada. Só consegui rodar usando um servidor, então evite esse método se tiver um computador normal (ou até mesmo um pessoal de alta qualidade). Em qualquer caso, a implementação desse método é a função ````cluster::clusGap````. 

O segundo método é o do "Cotovelo". Não é muito sofisticado, mas é potente. Plotamos o WCSS como uma função de $k$ e procuramos por uma inflexão na curva. Onde ela tiver um "cotovelo", é provavelmente o $k$ mais adequado. A função a seguir implementa o gráfico:

```{r}
wssplot <- function(data, nc=15, seed=1234){
  wss <- (nrow(data)-1)*sum(apply(data,2,var))
  for (i in 2:nc){
    set.seed(seed)
    wss[i] <- sum(kmeans(data, centers=i)$withinss)}
  
  plot(1:nc, wss, type="b", xlab="Number of Clusters",
       ylab="Within groups sum of squares")}
````

![Método do Cotovelo](https://i.imgur.com/nEBZbL3.png)

Agora que escolhemos o número 3, podemos finalmente ver se o modelo classifica bem cursos de medicina.

## Os finalmentes, rodando o modelo e resultados

Tendo 3 como o número mágico, podemos finalmente rodar o modelo. ````kmeans```` é um comando nativo do R, mas visualização pode ser melhor - afinal, é interessante _ver_ os agrupamentos. Para isso, vamos usar ````cluster::clusplot````:

```{r}
##### Inspecione o objeto

str(analise_kmeans)

##### Agora visualize os resultados

clusplot(final, analise_kmeans$cluster,
                        main='Procurando por 3 agrupamentos no ProUni',
                            color=TRUE,
                              shade=TRUE,
                                lines=0)

````
![Resultados](https://i.imgur.com/DO5ZdtC.png)

Se o leitor fizer o exercício de replicar esse post, vai poder ver que o algoritimo identificou todos os 122 cursos de medicina da amostra e inseriu por engano no mesmo cluster 44 cursos que não são de medicina. 

A performance é aceitável?



