<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Danielc on AZUL</title>
    <link>/authors/danielc/</link>
    <description>Recent content in Danielc on AZUL</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pt-br</language>
    <lastBuildDate>Mon, 24 Sep 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/authors/danielc/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Sazonalidade, x13, e dummies: Muito barulho por nada</title>
      <link>/2018/09/24/sazonalidade-x13-e-dummies-muito-barulho-por-nada/</link>
      <pubDate>Mon, 24 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/24/sazonalidade-x13-e-dummies-muito-barulho-por-nada/</guid>
      <description>Todo mundo já enfrentou uma série temporal que tinha sazonalidade. Sempre precisamos de uma maneira de dessazonalizar. Dois métodos vem a mente: o simples use dummies para cada período, faça uma regressão e pegue os resíduos e o elaborado, quase caixa preta, x13-SEATS. Mas, faz tanta diferença qual dos dois usar?
Neste post, eu vou dessazonalizar a série de capacidade instalada da FGV usando os dois métodos - e vamos comparar as diferenças.</description>
    </item>
    
    <item>
      <title>Identificação em VAR e Price Puzzle</title>
      <link>/2018/09/17/identifica%C3%A7%C3%A3o-em-var-e-price-puzzle/</link>
      <pubDate>Mon, 17 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/17/identifica%C3%A7%C3%A3o-em-var-e-price-puzzle/</guid>
      <description>O VAR (Vector Autoregression, em inglês; em tradução livre, autoregressão vetorial) é um método padrão em estudos empíricos em macroeconomia. VARs são simplesmente empilhamentos de variáveis nas quais estimamos uma autoregressão. Para solidificar a ideia, suponha que temos duas variáveis \(x_t,y_t\) em um vetor \(\mathbb{x_t} = (x_y \phantom{0} y_t)&amp;#39;\) um VAR seria:
\[\mathbf{x_t} = C\mathbf{x_{t-1}} + \mathbf{u_t}\]
Onde \(C\) é uma matriz \(2 \times 2\) e \(\mathbf{u_t}\) é um vetor de choques, possivelmente correlacionados.</description>
    </item>
    
    <item>
      <title>Por que usar o Julia?</title>
      <link>/2018/09/13/por-que-usar-o-julia/</link>
      <pubDate>Thu, 13 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/13/por-que-usar-o-julia/</guid>
      <description>Eu já fiz alguns posts em que eu usava a linguagem de programação Julia. O Julia é relativamente novo: o projeto começou em 2009 e a versão 1.0 foi lançada esse ano. Apesar disso, ela já é um relativamente conhecida. O Julia promete ter uma sintaxe clara e ser mais rápido do que linguagens como o Matlab e o R.
Eu sempre tomei como certo a afirmação do Julia de que ele era mais rápido que os concorrentes.</description>
    </item>
    
    <item>
      <title>Programação Dinâmica I</title>
      <link>/2018/09/08/programacao-dinamica-i/</link>
      <pubDate>Sat, 08 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/08/programacao-dinamica-i/</guid>
      <description>Este é o primeiro de uma série de posts que eu pretendo fazer sobre um tema interessante, complicado e que usa programação pesadamente - o que faz dele um carro chefe para a proposta desse blog: programação dinâmica. O nome engana: apesar de usarmos ferramentas computacionais para resolver o problema, a programação dinâmica trata de problemas de otimização no tempo. O nosso objetivo final vai ser resolver um problema de um agente otimizando a sua utilidade no tempo sem uma data final - o tempo vai para o infinito - sujeito à alguma restrição de recursos.</description>
    </item>
    
    <item>
      <title>O LASSO</title>
      <link>/2018/09/01/lasso/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/01/lasso/</guid>
      <description>Este post vai tratar de um método de machine learning muito interessante e relativamente simples: o LASSO. LASSO significa Least Absolute Shrinkage and Select Operator. Como o nome sugere, o LASSO seleciona quais regressores são relevantes e quais não são. Ou seja, suponha que você é um pesquisador que tem 50 variáveis que são possíveis candidatos a variáveis explicativas de uma variável de interesse. O LASSO permite que você dê os 50 regressores para o computador e ele escolha quais são os relevantes.</description>
    </item>
    
    <item>
      <title>Interpolação</title>
      <link>/2018/08/27/interpolacao/</link>
      <pubDate>Mon, 27 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/27/interpolacao/</guid>
      <description>Este post vai discutir sobre interpolação. Não é o post mais interessante deste blog. Mas ele é necessário para posts futuros.
A ideia de interpolação é literalmente “ligar os pontos”: dado um conjunto de pontos, procuramos uma função (ou um conjunto de funções) que passe por todos os pontos. Veja que a ideia é parecida com a de Mínimos Quadrados, mas com a diferença que mínimos quadrados não necessariamente passa por todos os pontos - ou sequer passa por qualquer um dos pontos.</description>
    </item>
    
    <item>
      <title>Viés de variáveis instrumentais</title>
      <link>/2018/08/19/vi%C3%A9s-de-vari%C3%A1veis-instrumentais/</link>
      <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/19/vi%C3%A9s-de-vari%C3%A1veis-instrumentais/</guid>
      <description>Como prometido no post anterior, vamos usar simulação para testar algumas coisas. A primeira delas é um problema curioso e (relativamente) pouco explorado: o viés ao usarmos muitos instrumentos em variáveis instrumentais. O excelente Mostly Harmless Econometrics, de Angrist e Pischke, conta com uma discussão sobre o tema na seção 4.6.4 - não surpreendentemente chamada de Bias of 2SLS.
Antes, uma recapitulação sobre variáveis instrumentais (se você não aprendeu sobre variáveis instrumentais, qualquer livro básico de econometria vai falar sobre o tópico): suponha que você tem o modelo \(y =x\beta+e\) e você sabe que \(E(ex) \neq 0\) - ou seja, temos um problema de endogenidade.</description>
    </item>
    
    <item>
      <title>Monte Carlo 101</title>
      <link>/2018/07/18/monte-carlo-101/</link>
      <pubDate>Wed, 18 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/07/18/monte-carlo-101/</guid>
      <description>Simulações Monte Carlo são uma excelente maneira de entender um novo conceito, bem como explorar propriedades de estimadores. Quando queremos entender as propriedades não assintóticas dos estimadores, são raros os casos em que temos soluções analíticas: Mínimos Quadrados Ordinários é um dos casos, que parcialmente justifica a popularidade do método. Em muitos casos, usamos simulações para entender as características de um estimador em amostras finitas. Esse post tenta prover uma ilustração de como criar simulações e usa-las.</description>
    </item>
    
  </channel>
</rss>