<!DOCTYPE html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<title>
  
     Uma introdução à Cross Validation | 
    AZUL
  
</title><meta name="description" content="Economia, Estatística, Programação"><meta name="author" content="danielc">

<link rel="apple-touch-icon" href="/apple-touch-icon.png" sizes="180x180">
<link rel="icon" href="/favicon-32x32.png " sizes="32x32" type="image/png">
<link rel="icon" href="/favicon-16x16.png" sizes="16x16" type="image/png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#0c344b">
<link rel="icon" href="/favicon.ico">

//styles, look here: https://cdnjs.com/libraries/highlight.js/9.12.0

<link href="/css/prism.css" rel="stylesheet" />




    
        
            <link rel="stylesheet" href="/dist/main.37ab3f61b95417873748.min.css">
        
    




<link rel="canonical" href="https://azul.netlify.app/2019/04/20/cross-validation/"><meta property="og:title" content="Uma introdução à Cross Validation" />
<meta property="og:description" content="Cross Validation (traduzido as vezes como Validação Cruzado e abreviado como CV) é um método bastante comum em Machine Learning para selecionar parâmetros ou hiperparâmetros. Eu já usei em outro post para o blog em que eu falei de LASSO, onde tinhamos que selecionar o parâmetro de penalização \(\lambda\).
A ideia do Cross Validation é simples: pegue seu conjunto de dados e divida em k blocos de tamanho igual (ou o mais igual possível se o número de observações não for um múltiplo de k)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://azul.netlify.app/2019/04/20/cross-validation/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2019-04-20T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2019-04-20T00:00:00&#43;00:00" />

<meta itemprop="name" content="Uma introdução à Cross Validation">
<meta itemprop="description" content="Cross Validation (traduzido as vezes como Validação Cruzado e abreviado como CV) é um método bastante comum em Machine Learning para selecionar parâmetros ou hiperparâmetros. Eu já usei em outro post para o blog em que eu falei de LASSO, onde tinhamos que selecionar o parâmetro de penalização \(\lambda\).
A ideia do Cross Validation é simples: pegue seu conjunto de dados e divida em k blocos de tamanho igual (ou o mais igual possível se o número de observações não for um múltiplo de k)."><meta itemprop="datePublished" content="2019-04-20T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2019-04-20T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="1028">
<meta itemprop="keywords" content="Cross Validation," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Uma introdução à Cross Validation"/>
<meta name="twitter:description" content="Cross Validation (traduzido as vezes como Validação Cruzado e abreviado como CV) é um método bastante comum em Machine Learning para selecionar parâmetros ou hiperparâmetros. Eu já usei em outro post para o blog em que eu falei de LASSO, onde tinhamos que selecionar o parâmetro de penalização \(\lambda\).
A ideia do Cross Validation é simples: pegue seu conjunto de dados e divida em k blocos de tamanho igual (ou o mais igual possível se o número de observações não for um múltiplo de k)."/>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>



</head>
<body>
    
<nav class="navbar navbar-expand-md navbar-light bg-light fixed-top shadow-sm" id="navbar-main-menu">
    <div class="container">
        <a class="navbar-brand font-weight-bold" href="https://azul.netlify.app/">AZUL</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#main-menu" aria-controls="main-menu" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="main-menu">
            <ul class="navbar-nav ml-auto">
                
                    <li class="nav-item"><a class="nav-link" href="/">Home</a></li>
                
                    <li class="nav-item"><a class="nav-link" href="/categories/">Categorias</a></li>
                
                    <li class="nav-item"><a class="nav-link" href="/about/">Sobre</a></li>
                
                    <li class="nav-item"><a class="nav-link" href="/tags/">Tags</a></li>
                
            
            </ul>
        </div>
    </div>
</nav>


    
<main class="content-page container pt-7 pb-5">
    
    <div class="row">
        <div class="col">
            <article>
                <div class="row justify-content-center">
                    <div class="col-lg-8">
                        <div class="meta text-muted mb-3">
                            <p class="created text-muted text-uppercase font-weight-bold mb-1">April 20, 2019</p>
                            <span class="mr-2"><i class="fas fa-book-open mr-2"></i>1028 palavras</span>
                            <span><i class="fas fa-clock mr-2"></i>5 mins</span>
                        </div>

                        <h1>Uma introdução à Cross Validation</h1>

                        <ul class="authors list-inline"><li class="list-inline-item mr-3">
                    <div class="media author"><div class="media-body">
                            <h5 class="name my-0"><a href="/authors/danielc/" class="small">Daniel Coutinho</a>
                            </h5></div>
                    </div>
                </li></ul>
                    </div>
                </div><div class="row justify-content-center">
                    <div class="col-lg-8">
                        <div class="content">
                            
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>


<p>Cross Validation (traduzido as vezes como Validação Cruzado e abreviado como CV) é um método bastante comum em Machine Learning para selecionar parâmetros ou hiperparâmetros. Eu já usei em outro <a href="https://azul.netlify.com/2018/09/16/lasso/">post para o blog em que eu falei de LASSO</a>, onde tinhamos que selecionar o parâmetro de penalização <span class="math inline">\(\lambda\)</span>.</p>
<p>A ideia do Cross Validation é simples: pegue seu conjunto de dados e divida em k blocos de tamanho igual (ou o mais igual possível se o número de observações não for um múltiplo de k). Estime o seu modelo para um certo número de parâmetros que são razoáveis em um bloco e veja qual a perda em alguma métrica (Erro Quadrático Médico, Erro Absoluto Médio, você escolhe) para os dados nos outros k-1 blocos. Faça isso para todos os blocos. A imagem abaixo ilustra a ideia (não é nenhuma obra de arte) para 5 blocos: a linha preta representa o conjunto de dados e as linhas vermelhas separam os blocos do Cross Validation. <strong>T</strong> indica que usamos aquele bloco numa dada iteração para “treinar” (ou estimar) o modelo e <strong>V</strong> que usamos aquele bloco para avaliar o desempenho do modelo. O modelo selecionado é o que performa melhor na média de todos os blocos.</p>
<p><img src="/post/cross-validation/CV_ilustrado.png" /></p>
<p>Veja que temos bons motivos para <em>não usar</em> o mesmo bloco que usamos para estimar o modelo para avaliar o modelo: dado o valor do parâmetro escolhido, em geral o algoritmo vai tentar escolher o melhor modelo para os dados. Nosso interesse é saber a performance do modelo em geral. Isso é verdade para várias aplicações: nós queremos bons modelos que façam previsão para o futuro, não para dentro da nossa amostra; queremos modelos explicativos em economia que não tenham válida apenas para aquela amostra de pessoas/período do tempo, mas sim para situações genéricas (o que é chamado de validade externa); etc.</p>
<p>Como tudo na vida, existem problemas com Cross Validation:</p>
<ol style="list-style-type: decimal">
<li><p>É computacionalmente intensivo. Se fazemos k blocos e cada modelo leva t segundos para estimar, então temos <span class="math inline">\(tk\)</span> de tempo para estimar. Se ainda decidimos estimar um último modelo usando o parâmetro escolhido por CV e a amostra toda, acabamos gastando <span class="math inline">\(t(k+1)\)</span>.</p></li>
<li><p>Se temos poucas observações, pode ser problemático deixar de fora um pedaço da amostra na hora de estimar. Com uma amostra de 100 e 5 blocos, teremos blocos de 20 observações. Um modelo com 10 variáveis nos deixaria com 10 graus de liberdade.</p></li>
<li><p>Talvez mais importante, o processo requer que os dados sejam independentes: uma estrutura de depedência temporal não permite embaralhar os dados de qualquer forma, por exemplo. Felizmente existem algumas maneiras de fazer Cross Validation que levam isso em conta - que eu não irei explorar por este ser um post introdutório ao assunto.</p></li>
</ol>
<p>Vamos ilustrar o Cross Validation para o parâmetro de regularização <span class="math inline">\(\lambda\)</span>. Veja que <code>glmnet</code>tem um comando interno que faz isso automaticamente, o <code>cv.glmnet</code>, mas como o meu propósito é ilustrativo, eu implemento na mão: vamos gerar um modelo com 50 variáveis, 1000 observações, e as 10 primeiras são relevantes com coeficiente igual a 1 e o resto irrelevante:</p>
<pre class = "line-numbers"><code class="language-r match-braces rainbow-braces">X &lt;- matrix(rnorm(50*1000),ncol=50)
betas &lt;- c(rep(1,10),rep(0,40))
y &lt;- X%*%betas + rnorm(1000)</code></pre>
<p>O código que vai escolher o <span class="math inline">\(\lambda\)</span> vai primeiro quebrar a amostra em 5 pedaços e depois fazer um for para estimar o modelo em cada um dos pedaços e testar a capacidade preditiva de cada um. Veja que precisamos usar os dados inteiros: não podemos misturar y[1] com x[10,], por exemplo. Para escolher os blocos, eu vou mandar o R fazer um sample de números 1:número de observações e quebrar isso em cinco blocos:</p>
<pre class = "line-numbers"><code class="language-r match-braces rainbow-braces">dados &lt;- cbind(y,X)

valores_cv &lt;- sample(1:1000,size = 1000,replace = F)</code></pre>
<p>Veja que se eu deixar o <code>glmnet</code> escolher o lambda automaticamente em cada replicação do CV, ele vai escolher dependente dos dados e não poderemos comparar qual é o melhor. Então eu faço uma primeira passagem do glmnet por todo os dados com o objetivo de escolher um conjunto de lambdas que vai ser testado (isso é igual ao que o <code>cv.glmnet</code>faz, diga-se de passagem)</p>
<pre class = "line-numbers"><code class="language-r match-braces rainbow-braces">tic()

modelo &lt;- glmnet(X,y)
lambdas &lt;- modelo$lambda

lambda_sel &lt;- rep(0,5)

for(i in 1:5){
  amostra &lt;- valores_cv[(1:200)+200*(i-1)]
  dados_train &lt;- dados[amostra,]
  dados_vali &lt;- dados[-amostra,] 
  modelo_cv &lt;- glmnet(dados_train[,2:ncol(dados_train)],dados_train[,1],lambda = lambdas)
  x_aux &lt;- cbind(1,dados_vali[,2:ncol(dados_vali)])
  u &lt;- dados_vali[,1] - x_aux%*%coef(modelo_cv)
  ssr &lt;- colSums(u^2)
  sel_indice &lt;- which.min(ssr) #indice de qual modelo foi melhor
  lambda_sel[i] &lt;- lambdas[sel_indice]
}

modelo_final &lt;- glmnet(X,y,lambda = mean(lambda_sel))

tempo &lt;- toc()</code></pre>
<pre ><code >## 0.121 sec elapsed</code></pre>
<pre class = "line-numbers"><code class="language-r match-braces rainbow-braces">tempo &lt;- tempo$toc - tempo$tic</code></pre>
<p>(A sugestão de usar o tictoc para pegar o tempo foi do Pedro). O tempo de execução é até bastante rápido, ficando em 0.121 segundos. Vamos fazer um plot dos coeficientes escolhidos:</p>
<pre class = "line-numbers"><code class="language-r match-braces rainbow-braces">plot(coef(modelo_final)[-1], ylab = " ")</code></pre>
<p><img src="/post/cross-validation/2019-04-19-cross-validation_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Aparentemente o cross validation conseguiu recuperar quase todos os coeficientes corretos. Vamos testar:</p>
<pre class = "line-numbers"><code class="language-r match-braces rainbow-braces">teste1 &lt;- mean(coef(modelo_final)[2:11] !=0)
teste2 &lt;- mean(coef(modelo_final)[12:51] == 0)
teste &lt;- ifelse(teste1 + teste2 ==2,1,0)

tabela &lt;- c(teste1,teste2,teste)*100
names(tabela) &lt;- c("Não Zeros certos", "Zeros Certos", "Modelo Certo?")

knitr::kable(tabela,caption = "Todos os valores em porcentagem")</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-6">Table 1: </span>Todos os valores em porcentagem</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Não Zeros certos</td>
<td align="right">100</td>
</tr>
<tr class="even">
<td align="left">Zeros Certos</td>
<td align="right">90</td>
</tr>
<tr class="odd">
<td align="left">Modelo Certo?</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p>Veja que obviamente não podemos avaliar a qualidade do Cross Validation com base em uma única simulação. Nosso objetivo aqui é ilustrar a técnica. No post de <a href="https://azul.netlify.com/2018/09/16/lasso/">LASSO</a> e em post futuro sobre um irmão do LASSO, eu discuto a qualidade do CV para selecionar o parâmetro de regularização.</p>
<p>Veja que Cross Validation não é usado apenas para escolher parâmetros de regularização do LASSO: quase qualquer hiperparâmetro de um modelo pode ser selecionado por cross validation. Árvores de regressão são outro contexto em que o Cross Validation é usado, por exemplo. Mas como de praxe, existem hipóteses das quais o CV parte. Uma delas é independência entre as observações, que é inadequada em muitos casos com dados econômicos.</p>
<p>Com esse (relativamente) curto post, eu espero que o leitor tenha o mínimo de noção como o Cross Validation é usado e quais as suas limitações. Este post é introdutório: diversos livros falam de Cross Validation, inclusive o <a href="https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12.pdf">Elements of Statistical Learning</a>, que você pode baixar de maneira 100% legal pelo link. Cross Validation é muito comum em técnicas de Machine Learning e portanto serão frequentes no blog.</p>

                        </div><div class="tags my-3"><a class="badge badge-pill badge-light border mr-2" href="/tags/cross-validation">
                                    <i class="fas fa-tag mr-2"></i>Cross Validation
                                </a></div><ul class="share nav my-3 justify-content-end">
        <li class="nav-item">
            <a class="nav-link" target="_blank" href="https://twitter.com/intent/tweet?url=https%3a%2f%2fazul.netlify.app%2f2019%2f04%2f20%2fcross-validation%2f&text=Uma%20introdu%c3%a7%c3%a3o%20%c3%a0%20Cross%20Validation">
              <i class="fa-fw fab fa-twitter"></i>
          </a>
        </li>
        <li class="nav-item">
            <a class="nav-link" target="_blank" href="https://www.linkedin.com/shareArticle?url=https%3a%2f%2fazul.netlify.app%2f2019%2f04%2f20%2fcross-validation%2f&title=Uma%20introdu%c3%a7%c3%a3o%20%c3%a0%20Cross%20Validation">
                <i class="fa-fw fab fa-linkedin-in"></i>
            </a>
        </li>
        <li class="nav-item">
            <a class="nav-link" target="_blank" href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fazul.netlify.app%2f2019%2f04%2f20%2fcross-validation%2f&t=Uma%20introdu%c3%a7%c3%a3o%20%c3%a0%20Cross%20Validation">
                <i class="fa-fw fab fa-facebook-f"></i>
            </a>
        </li>
        <li class="nav-item">
            <a class="nav-link" target="_blank" href="https://reddit.com/submit?url=https%3a%2f%2fazul.netlify.app%2f2019%2f04%2f20%2fcross-validation%2f&title=Uma%20introdu%c3%a7%c3%a3o%20%c3%a0%20Cross%20Validation">
                <i class="fa-fw fab fa-reddit-alien"></i>
            </a>
        </li>
    </nav>
                    </div>
                </div>

                <div class="row justify-content-center">
                    <div class="col-lg-8">
                        
                    </div>
                </div></article>
        </div>
    </div>

    
</main>


    <footer class="footer text-center bg-dark py-6">
    <div class="container">
        <div class="row">
            <div class="col">
                <ul class="list-inline">
                    <li class="list-inline-item"><a href="https://azul.netlify.app/index.xml" rel="alternate" type="application/rss+xml" class="icons d-block">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a></li><li class="list-inline-item">
                            <a href="https://github.com/danmrc/azul/tree/master/C%C3%B3digos" class="icons d-block">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                </ul>

                <p class="text-muted">
                    
                        Copyright © 2008–2020, Pedro Cavalcante & Daniel Coutinho; all rights reserved.
                    
                </p>

                <p class="text-muted">
                Powered by <a href="https://gohugo.io" target="_blank">Hugo</a> with <a href="https://github.com/puresyntax71/hugo-theme-chunky-poster" target="_blank">Chunky Poster</a>.
                </p>
            </div>
        </div>
    </div>
</footer>

    
    
        
            <script src="/dist/main.d608eadfe5ac0688902e.min.js"></script>
        
    






<script src="/js/prism.js"></script>


    
</body>
</html>
