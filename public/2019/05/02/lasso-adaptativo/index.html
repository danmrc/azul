<!DOCTYPE html>
<html lang="pt-br">
	<head>
		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		
		<meta name="author" content="Daniel Coutinho e Pedro Cavalcante">
		<meta name="description" content="Economia, Estatística, Programação">
		<meta name="generator" content="Hugo 0.55.5" />
		<title>LASSO Adaptativo e Critérios de Informação para LASSO &middot; AZUL</title>
		<link rel="shortcut icon" href="/images/favicon.ico">
		<link rel="stylesheet" href="/css/style.css">
		<link rel="stylesheet" href="/css/highlight.css">

		
		<link rel="stylesheet" href="/css/monosocialiconsfont.css">
		

		

		
	</head>

    <body>
       <nav class="main-nav">
	
	
		<a href='/'> <span class="arrow">←</span>Início</a>
	
	<a href='/post'>Arquivo</a>
	<a href='/tags'>Tags</a>
	<a href='/about'>Sobre</a>
  <a href='/categories'>Categorias</a>
  
	

	
</nav>


        <section id="wrapper" class="post">
            <article>
                <header>
                    <h1>
                        LASSO Adaptativo e Critérios de Informação para LASSO
                    </h1>
                    <h2 class="headline">
                    May 2, 2019 00:00
                    · 1710 words
                    · 9 minute read
                      <span class="tags">
                      
                      
                          
                              <a href="/tags/lasso">LASSO</a>
                          
                      
                      
                      </span>
                    </h2>
                </header>
                
                  
                
                <section id="post-body">
                    


<p>Em um <a href="https://azul.netlify.com/2018/09/16/lasso/">post anterior</a>, eu falei do LASSO (Least Absolute Shrinkage and Select Operator). Como vamos explorar uma variação do LASSO hoje, eu vou repetir o problema que o LASSO resolvia:</p>
<p><span class="math display">\[\hat{\beta}_{LASSO} \in \arg \min_{\beta} \displaystyle \sum_{i=1}^n (y_i - x_i \beta)^2 + \lambda \sum_{k=0}^p |\beta_k|\]</span></p>
<p>(Onde <span class="math inline">\(|.|\)</span> é o valor absoluto do termo). E como eu já disse, o LASSO nos fornece uma maneira de selecionar quais variáveis entram no modelo ou não. Vamos fazer um pequeno teste com o LASSO: eu vou gerar 50 variáveis normais, independentes, e dessas dez - as dez primeiras - eu colocarei <span class="math inline">\(\beta=1\)</span>. As outra vão ser irrelevantes para o problema e vão ter <span class="math inline">\(\beta=0\)</span>. O tamanho da amostra vai ser igual a 100.</p>
<p>Como de praxe, nós podemos ter diversos objetivos ao estimar um modelo. Eu vou comparar 3 coisas: a quantidade de vezes que o LASSO coloca as variáveis relevantes, a quantidade de vezes que ele exclui as variáveis irrelevantes e quando ele obtém o modelo certo - o que exige colocar todo mundo que é relevante <strong>e</strong> excluir todos os irrelevantes. Vou fazer só 500 replicações e usar o Cross Validation (que eu já discuti aqui) para escolher o <span class="math inline">\(\lambda\)</span>:</p>
<pre class="r"><code>library(glmnet)

coeficientes &lt;- Matrix(0,ncol=500,nrow=51)

for(i in 1:500){
  x &lt;- matrix(rnorm(50*100),ncol = 50) #gerando x
  betas &lt;- c(rep(1,10),rep(0,40)) #
  y &lt;- x%*%betas + rnorm(100)
  modelo &lt;- cv.glmnet(x,y) #estimando usando LASSO e Cross Validation
  coeficientes[,i] &lt;- coef(modelo)
}

#Fim da simulação

analise &lt;- matrix(0,ncol=3,nrow=500)
colnames(analise)&lt;- c(&quot;Não zeros certos&quot;,&quot;Zeros certos&quot;, &quot;Modelo certo?&quot;)

for(i in 1:500){
  analise[i,1]&lt;- mean(coeficientes[2:11,i] != 0)
  analise[i,2]&lt;- mean(coeficientes[12:51,i] == 0)
  analise[i,3]&lt;- ifelse(analise[i,1]+analise[i,2] == 2,1,0)
}

tabela_final &lt;- colMeans(analise)*100
knitr::kable(tabela_final,caption = &quot;Os valores estão em porcentagem&quot;)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-1">Table 1: </span>Os valores estão em porcentagem</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Não zeros certos</td>
<td align="right">100.000</td>
</tr>
<tr class="even">
<td>Zeros certos</td>
<td align="right">83.525</td>
</tr>
<tr class="odd">
<td>Modelo certo?</td>
<td align="right">0.600</td>
</tr>
</tbody>
</table>
<p>O LASSO sempre inclui as variáveis relevantes, e exclui as variáveis irrelevantes em 84% das vezes. Mesmo assim, a proporção de vezes que o LASSO consegue recuperar o modelo correto é um por volta de 1%. Isso parece esquisito a primeira vista, mas lembre que recuperar o modelo certo envolve <em>acertar todas as relevantes e todas as irrelevantes</em>. Se tivermos 50 variáveis e 500 replicações e em toda replicação o LASSO colocar apenas umas variável irrelevante no modelo, nós teríamos 98% de zeros certos (<span class="math inline">\(49/50\)</span>) e exatamente 0 modelos certos.</p>
<p>Parte do problema é que o LASSO penaliza todos os coeficientes igualmente, usando o <span class="math inline">\(\lambda\)</span>. Nós esperaríamos que algumas variáveis sejam mais importantes que outras - e isso pode vir a priori ou ser dito pelos dados. O LASSO adaptativo (adaLASSO) adiciona pesos (<span class="math inline">\(\omega\)</span>) para cada uma das variáveis na penalidade. Logo o novo problema a ser resolvido é:</p>
<p><span class="math display">\[\hat{\beta}_{adaLASSO} \in \arg \min_{\beta} \displaystyle \sum_{i=1}^n (y_i - x_i \beta)^2 + \lambda \sum_{k=0}^p \frac{|\beta_k|}{\omega_k}\]</span></p>
<p>A única exigência desses pesos é que eles sejam positivos. Veja que nós temos um novo parâmetro a escolher, os pesos. Eis um algoritmo muito simples que gera os pesos baseado nos dados e usa o LASSO:</p>
<ol style="list-style-type: decimal">
<li>Estime o modelo usando LASSO. Guarde os coeficientes, que eu chamarei de <span class="math inline">\(\beta_{LASSO}\)</span></li>
<li>Defina <span class="math inline">\(\omega_k = \frac{1}{|\beta_{LASSO}|}\)</span></li>
<li>Estime o adaLASSO usando os pesos definidos em 2.</li>
</ol>
<p>A boa notícia é que o <em>glmnet</em> já nos oferece uma opção para colocar o peso, via o argumento <em>penalty.factor</em>. Nosso trabalho é basicamente reduzido a escrever umas duas linhas de código a mais: uma que faz o LASSO de “primeiro estágio” e outra que define os pesos.</p>
<p>Uma coisa deve ficar evidente: da maneira que os pesos foram estabelecidos no meu algoritmo, coeficientes que são zerados pelo LASSO serão automaticamente excluídos pelo LASSO adaptativo: teremos como peso <span class="math inline">\(1/0\)</span> (com perdão aos matemáticos), que no limite é infinito. Como o LASSO não excluiu as variáveis relevantes em nenhum caso, não vamos nos preocupar. Mas é possível imaginar situações em que o LASSO poderia ter problemas (pense em coeficientes altissimamente correlacionados em uma amostra relativamente pequena). Outra coisa que deve ficar clara é que precisamos selecionar o <span class="math inline">\(\lambda\)</span> agora duas vezes, uma para o LASSO e outra para a etapa “adaptativa” do LASSO!</p>
<p>Vamos repetir a simulação ali de cima, mas usando o adaLASSO. Em ambos os estágios eu vou usar o Cross Validation:</p>
<pre class="r"><code>coeficientes_adalasso &lt;- Matrix(0,ncol=500,nrow=51)

for(i in 1:500){
  x &lt;- matrix(rnorm(50*100),ncol = 50) #gerando x
  betas &lt;- c(rep(1,10),rep(0,40)) #
  y &lt;- x%*%betas + rnorm(100)
  primeiro_estagio &lt;- cv.glmnet(x,y) #estimando usando LASSO e Cross Validation
  pesos &lt;- 1/abs(coef(primeiro_estagio)[-1,]) #veja que eu tenho que jogar fora o intercepto
  adalasso &lt;- cv.glmnet(x,y,penalty.factor = pesos)
  coeficientes_adalasso[,i] &lt;- coef(adalasso)
}

#Fim da simulação

analise &lt;- matrix(0,ncol=3,nrow=500)
colnames(analise)&lt;- c(&quot;Não zeros certos&quot;,&quot;Zeros certos&quot;, &quot;Modelo certo?&quot;)

for(i in 1:500){
  analise[i,1]&lt;- mean(coeficientes_adalasso[2:11,i] != 0)
  analise[i,2]&lt;- mean(coeficientes_adalasso[12:51,i] == 0)
  analise[i,3]&lt;- ifelse(analise[i,1]+analise[i,2] == 2,1,0)
}

tabela_final &lt;- colMeans(analise)*100
knitr::kable(tabela_final,caption = &quot;Os valores estão em porcentagem&quot;)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-2">Table 2: </span>Os valores estão em porcentagem</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Não zeros certos</td>
<td align="right">100.00</td>
</tr>
<tr class="even">
<td>Zeros certos</td>
<td align="right">96.81</td>
</tr>
<tr class="odd">
<td>Modelo certo?</td>
<td align="right">61.00</td>
</tr>
</tbody>
</table>
<p>A performance do LASSO adaptativo é muito melhor que a do LASSO: em aproximadamente 60% dos casos agora recuperamos o modelo correto, contra um pouco mais de 1% dos casos para o LASSO. O adaLASSO é uma modificação extremamente simples do algoritmo do LASSO que gera excelente resultados. Veja que a escolha do Cross Validation aqui é apenas pela conveniência do glmnet já trazer o Cross Validation. Veja que implementar um critério de informação é extremamente simples. Eu vou descrever o algoritmo para o LASSO, e para o adaLASSO basta juntar os dois procedimentos:</p>
<ol style="list-style-type: decimal">
<li>Estime o modelo usando LASSO via o glmnet (não o cv.glmnet!). Isso vai devolver uma matriz de coeficientes, de dimensão <span class="math inline">\(p \times L\)</span>, onde <span class="math inline">\(L\)</span> é a quantidade de lambdas que a função usou.</li>
<li>Calcule o resíduo para cada modelo estimado <span class="math inline">\(u_l = y - X\beta_l\)</span></li>
<li>Calcule a soma do quadrado dos erros para cada modelo <span class="math inline">\(SSR = \sum_{i=1}^{n} u_i^2\)</span>.</li>
<li>Crie um vetor que tem a quantidade de coeficientes não zeros para cada modelo estimado. Vamos nos referir a cada entrada desse modelo como <span class="math inline">\(s\)</span>.</li>
<li>Calcule <span class="math inline">\(IC = n \ln(SSR) + cs\)</span> para cada modelo, onde c é o critério de informação escolhido</li>
<li>Escolha o lambda que minimiza o valor de IC</li>
</ol>
<p>Vamos escrever uma função que faz cada um dos passos. Veja que você não precisa fazer isso: existe um pacote excelente que já implementa isso no GitHub chamado <a href="https://github.com/gabrielrvsc/HDeconometrics">HDeconometrics</a>, mantido pelo Gabriel Vasconcelos. Mas seguindo o espírito do blog, eu vou implementar “no braço”. Eu vou permitir que o usuário escolha qualquer um dos 3 critérios, e para isso eu usarei uns if:</p>
<pre class="r"><code>ic_glmnet &lt;- function(x,y,penalty.factor,ic){
  require(glmnet)
  n &lt;- length(y)
  modelo &lt;- glmnet(x,y) #passo 1
  #passo 2
  x_aux &lt;- cbind(1,x)
  u &lt;- y - x_aux%*%coef(modelo)
  #passo 3
  ssr &lt;- colSums(u^2)
  #passo 4
  conj_ativo &lt;- colSums(coef(modelo) !=0)
  #vamos permitir o usuário escolha qual critério de informação vai ser usado
  if(ic == &quot;aic&quot;|ic==&quot;AIC&quot;){
    ic_val &lt;- 2} else if(ic==&quot;bic&quot;|ic==&quot;BIC&quot;){
      ic_val &lt;- log(n)
    } else if(ic == &quot;hqc&quot;|ic == &quot;HQC&quot;){
      ic_val &lt;- 2* log(log(n))
    } else{
      stop(&quot;IC not implemented&quot;)
    }
  #passo 5
  val &lt;- n*log(ssr)+ic_val*conj_ativo
  #passo 6
  selecionado &lt;- which.min(val)
  return(list(&quot;modelo_selecionado&quot; = coef(modelo)[,selecionado],&quot;modelo_glmnet&quot; = modelo, &quot;lambda_selecionado&quot; = modelo$lambda[selecionado]))
}</code></pre>
<p>Veja que eu faço a função retorna os coeficientes escolhidos, o modelo inteiro escolhido e o <span class="math inline">\(\lambda\)</span> escolhido ( o motivo para isso vai ficar claro). Vamos fazer um pequeno teste da nossa função:</p>
<pre class="r"><code>x &lt;- matrix(rnorm(50*100),ncol = 50) #gerando x
betas &lt;- c(rep(1,10),rep(0,40)) #
y &lt;- x%*%betas + rnorm(100)
teste &lt;- ic_glmnet(x,y,ic=&quot;BIC&quot;)</code></pre>
<pre><code>## Carregando pacotes exigidos: glmnet</code></pre>
<pre><code>## Carregando pacotes exigidos: Matrix</code></pre>
<pre><code>## Carregando pacotes exigidos: foreach</code></pre>
<pre><code>## Loaded glmnet 2.0-16</code></pre>
<pre class="r"><code>teste$modelo_selecionado</code></pre>
<pre><code>## (Intercept)          V1          V2          V3          V4          V5 
##  0.02919496  0.80721826  0.72118478  1.03292107  1.01925350  1.02434786 
##          V6          V7          V8          V9         V10         V11 
##  0.88267714  0.97021225  1.02600355  0.82197093  1.04430256  0.00000000 
##         V12         V13         V14         V15         V16         V17 
##  0.00000000  0.00000000  0.00000000 -0.07179414 -0.02062124 -0.11321705 
##         V18         V19         V20         V21         V22         V23 
## -0.05150767 -0.07230270 -0.10303200  0.08321580  0.00000000 -0.04758250 
##         V24         V25         V26         V27         V28         V29 
##  0.00000000  0.13620516  0.01186514  0.00000000  0.00000000  0.04777503 
##         V30         V31         V32         V33         V34         V35 
##  0.15935506 -0.15618481  0.00000000  0.00000000  0.00000000  0.12979546 
##         V36         V37         V38         V39         V40         V41 
##  0.00000000 -0.07786625  0.00000000 -0.13100984 -0.11033866  0.00000000 
##         V42         V43         V44         V45         V46         V47 
##  0.00000000  0.00000000  0.18164362 -0.04883286  0.05119821  0.00000000 
##         V48         V49         V50 
##  0.00000000  0.20137211  0.03448675</code></pre>
<p>E uma simulação, com uma mudança: nós não vamos escolher o <span class="math inline">\(\lambda\)</span> duas vezes. Nós vamos repetir o <span class="math inline">\(\lambda\)</span> escolhido no primeiro estágio para o segundo estágio. Isso tem dois objetivos:</p>
<ol style="list-style-type: decimal">
<li>Isola o efeito da seleção do lambda dos efeitos da pessagem do LASSO adaptativo</li>
<li>Ao invés de termos de selecionar os paramêtros duas vezes, selecionamos apenas uma vez.</li>
</ol>
<p>Vamos a simulação:</p>
<pre class="r"><code>coeficientes_adalasso_bic &lt;- Matrix(0,ncol=500,nrow=51)

for(i in 1:500){
  x &lt;- matrix(rnorm(50*100),ncol = 50) #gerando x
  betas &lt;- c(rep(1,10),rep(0,40)) #
  y &lt;- x%*%betas + rnorm(100)
  primeiro_estagio &lt;- ic_glmnet(x,y,ic = &quot;BIC&quot;) #estimando usando LASSO e BIC
  pesos &lt;- 1/abs(primeiro_estagio$modelo_selecionado[-1]) #veja que eu tenho que jogar fora o intercepto
  adalasso &lt;- glmnet(x,y,lambda = primeiro_estagio$lambda_selecionado,penalty.factor = pesos)
  coeficientes_adalasso_bic[,i] &lt;- coef(adalasso)
}

#Fim da simulação

analise &lt;- matrix(0,ncol=3,nrow=500)
colnames(analise)&lt;- c(&quot;Não zeros certos&quot;,&quot;Zeros certos&quot;, &quot;Modelo certo?&quot;)

for(i in 1:500){
  analise[i,1]&lt;- mean(coeficientes_adalasso_bic[2:11,i] != 0)
  analise[i,2]&lt;- mean(coeficientes_adalasso_bic[12:51,i] == 0)
  analise[i,3]&lt;- ifelse(analise[i,1]+analise[i,2] == 2,1,0)
}

tabela_final &lt;- colMeans(analise)*100
knitr::kable(tabela_final,caption = &quot;Os valores estão em porcentagem&quot;)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-5">Table 3: </span>Os valores estão em porcentagem</caption>
<thead>
<tr class="header">
<th></th>
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Não zeros certos</td>
<td align="right">100.000</td>
</tr>
<tr class="even">
<td>Zeros certos</td>
<td align="right">95.375</td>
</tr>
<tr class="odd">
<td>Modelo certo?</td>
<td align="right">42.400</td>
</tr>
</tbody>
</table>
<p>Veja que o BIC é bastante bem sucedido em recuperar o modelo certo. Veja que como mantivemos a penalidade parada, todo o ganho vem de acertar os pesos melhor, ilustrando bem qual é o segredo do adaLASSO. Apesar disso, ele é pior do que o Cross Validation. Isso vem com duas observações, que já foram discutidas no post de Cross Validation mas eu repito aqui:</p>
<ol style="list-style-type: decimal">
<li>CV é um processo computacionalmente intensivo: quebre em blocos os seus dados, estime o modelo repetidas vezes.</li>
<li>Mais importante, Cross Validation supõe <em>independência</em> entre as observações, ou seja, não podemos usar ele para dados de séries temporais</li>
</ol>
<p>O BIC não sofre de nenhum desses problemas, o que faz dele uma alternativa atraente para selecionar modelos com LASSO adaptativo.</p>
<p>Esse é um post que aborda duas coisas: LASSO adaptativo e seleção do parâmetro de penalidade via critérios de informação. Ambos tem aplicações interessantes e não precisam ser empregadas em conjunto.</p>
<p>Mostramos como o adaLASSO é bastante superior ao LASSO em seleção de modelos. Uma pergunta justa é se a diferença de previsão dos modelos são tão diferentes assim…</p>

                </section>
            </article>

            
                <a class="twitter" href="https://twitter.com/intent/tweet?text=%2f2019%2f05%2f02%2flasso-adaptativo%2f - LASSO%20Adaptativo%20e%20Crit%c3%a9rios%20de%20Informa%c3%a7%c3%a3o%20para%20LASSO "><span class="icon-twitter"> tweet</span></a>

<a class="facebook" href="#" onclick="
    window.open(
      'https://www.facebook.com/sharer/sharer.php?u='+encodeURIComponent(location.href),
      'facebook-share-dialog',
      'width=626,height=436');
    return false;"><span class="icon-facebook-rect"> Share</span>
</a>

            

            

            

            <footer id="footer">
    
        <div id="social">

	
	
    
    <a class="symbol" href="https://github.com/danmrc/azul/tree/master/C%C3%B3digos">
        github
    </a>
    


</div>

    
    <p class="small">
    
       © Copyright 2019 <i class="fa fa-heart" aria-hidden="true"></i> Daniel Coutinho e Pedro Cavalcante
    
    </p>
    <p class="small">
        Powered by <a href="http://www.gohugo.io/">Hugo</a> Theme By <a href="https://github.com/nodejh/hugo-theme-cactus-plus">nodejh</a>
    </p>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
</footer>

        </section>

        <script src="/js/jquery-3.3.1.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>




  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-123754589-1', 'auto');
	
	ga('send', 'pageview');
}
</script>





    </body>
</html>
