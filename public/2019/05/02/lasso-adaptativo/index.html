<!DOCTYPE html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<title>
  
     LASSO Adaptativo e Critérios de Informação para LASSO | 
    AZUL
  
</title><meta name="description" content="Economia, Estatística, Programação"><meta name="author" content="danielc">

<link rel="apple-touch-icon" href="/apple-touch-icon.png" sizes="180x180">
<link rel="icon" href="/favicon-32x32.png " sizes="32x32" type="image/png">
<link rel="icon" href="/favicon-16x16.png" sizes="16x16" type="image/png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#0c344b">
<link rel="icon" href="/favicon.ico">

//styles, look here: https://cdnjs.com/libraries/highlight.js/9.12.0

<link href="/css/prism.css" rel="stylesheet" />




    
        
            <link rel="stylesheet" href="/dist/main.37ab3f61b95417873748.min.css">
        
    




<link rel="canonical" href="https://azul.netlify.app/2019/05/02/lasso-adaptativo/"><meta property="og:title" content="LASSO Adaptativo e Critérios de Informação para LASSO" />
<meta property="og:description" content="Em um post anterior, eu falei do LASSO (Least Absolute Shrinkage and Select Operator). Como vamos explorar uma variação do LASSO hoje, eu vou repetir o problema que o LASSO resolvia:
\[\hat{\beta}_{LASSO} \in \arg \min_{\beta} \displaystyle \sum_{i=1}^n (y_i - x_i \beta)^2 &#43; \lambda \sum_{k=0}^p |\beta_k|\]
(Onde \(|.|\) é o valor absoluto do termo). E como eu já disse, o LASSO nos fornece uma maneira de selecionar quais variáveis entram no modelo ou não." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://azul.netlify.app/2019/05/02/lasso-adaptativo/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2019-05-02T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2019-05-02T00:00:00&#43;00:00" />

<meta itemprop="name" content="LASSO Adaptativo e Critérios de Informação para LASSO">
<meta itemprop="description" content="Em um post anterior, eu falei do LASSO (Least Absolute Shrinkage and Select Operator). Como vamos explorar uma variação do LASSO hoje, eu vou repetir o problema que o LASSO resolvia:
\[\hat{\beta}_{LASSO} \in \arg \min_{\beta} \displaystyle \sum_{i=1}^n (y_i - x_i \beta)^2 &#43; \lambda \sum_{k=0}^p |\beta_k|\]
(Onde \(|.|\) é o valor absoluto do termo). E como eu já disse, o LASSO nos fornece uma maneira de selecionar quais variáveis entram no modelo ou não."><meta itemprop="datePublished" content="2019-05-02T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2019-05-02T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="1704">
<meta itemprop="keywords" content="LASSO," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="LASSO Adaptativo e Critérios de Informação para LASSO"/>
<meta name="twitter:description" content="Em um post anterior, eu falei do LASSO (Least Absolute Shrinkage and Select Operator). Como vamos explorar uma variação do LASSO hoje, eu vou repetir o problema que o LASSO resolvia:
\[\hat{\beta}_{LASSO} \in \arg \min_{\beta} \displaystyle \sum_{i=1}^n (y_i - x_i \beta)^2 &#43; \lambda \sum_{k=0}^p |\beta_k|\]
(Onde \(|.|\) é o valor absoluto do termo). E como eu já disse, o LASSO nos fornece uma maneira de selecionar quais variáveis entram no modelo ou não."/>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>



</head>
<body>
    
<nav class="navbar navbar-expand-md navbar-light bg-light fixed-top shadow-sm" id="navbar-main-menu">
    <div class="container">
        <a class="navbar-brand font-weight-bold" href="https://azul.netlify.app/">AZUL</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#main-menu" aria-controls="main-menu" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="main-menu">
            <ul class="navbar-nav ml-auto">
                
                    <li class="nav-item"><a class="nav-link" href="/">Home</a></li>
                
                    <li class="nav-item"><a class="nav-link" href="/categories/">Categorias</a></li>
                
                    <li class="nav-item"><a class="nav-link" href="/about/">Sobre</a></li>
                
                    <li class="nav-item"><a class="nav-link" href="/tags/">Tags</a></li>
                
            
            </ul>
        </div>
    </div>
</nav>


    
<main class="content-page container pt-7 pb-5">
    
    <div class="row">
        <div class="col">
            <article>
                <div class="row justify-content-center">
                    <div class="col-lg-8">
                        <div class="meta text-muted mb-3">
                            <p class="created text-muted text-uppercase font-weight-bold mb-1">May 2, 2019</p>
                            <span class="mr-2"><i class="fas fa-book-open mr-2"></i>1704 palavras</span>
                            <span><i class="fas fa-clock mr-2"></i>8 mins</span>
                        </div>

                        <h1>LASSO Adaptativo e Critérios de Informação para LASSO</h1>

                        <ul class="authors list-inline"><li class="list-inline-item mr-3">
                    <div class="media author"><div class="media-body">
                            <h5 class="name my-0"><a href="/authors/danielc/" class="small"></a>
                            </h5></div>
                    </div>
                </li></ul>
                    </div>
                </div><div class="row justify-content-center">
                    <div class="col-lg-8">
                        <div class="content">
                            
<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>
<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>


<p>Em um <a href="https://azul.netlify.com/2018/09/16/lasso/">post anterior</a>, eu falei do LASSO (Least Absolute Shrinkage and Select Operator). Como vamos explorar uma variação do LASSO hoje, eu vou repetir o problema que o LASSO resolvia:</p>
<p><span class="math display">\[\hat{\beta}_{LASSO} \in \arg \min_{\beta} \displaystyle \sum_{i=1}^n (y_i - x_i \beta)^2 + \lambda \sum_{k=0}^p |\beta_k|\]</span></p>
<p>(Onde <span class="math inline">\(|.|\)</span> é o valor absoluto do termo). E como eu já disse, o LASSO nos fornece uma maneira de selecionar quais variáveis entram no modelo ou não. Vamos fazer um pequeno teste com o LASSO: eu vou gerar 50 variáveis normais, independentes, e dessas dez - as dez primeiras - eu colocarei <span class="math inline">\(\beta=1\)</span>. As outra vão ser irrelevantes para o problema e vão ter <span class="math inline">\(\beta=0\)</span>. O tamanho da amostra vai ser igual a 100.</p>
<p>Como de praxe, nós podemos ter diversos objetivos ao estimar um modelo. Eu vou comparar 3 coisas: a quantidade de vezes que o LASSO coloca as variáveis relevantes, a quantidade de vezes que ele exclui as variáveis irrelevantes e quando ele obtém o modelo certo - o que exige colocar todo mundo que é relevante <strong>e</strong> excluir todos os irrelevantes. Vou fazer só 500 replicações e usar o Cross Validation (que eu já discuti aqui) para escolher o <span class="math inline">\(\lambda\)</span>:</p>
<pre class = "line-numbers"><code class="language-r match-braces rainbow-braces">library(glmnet)

coeficientes &lt;- Matrix(0,ncol=500,nrow=51)

for(i in 1:500){
  x &lt;- matrix(rnorm(50*100),ncol = 50) #gerando x
  betas &lt;- c(rep(1,10),rep(0,40)) #
  y &lt;- x%*%betas + rnorm(100)
  modelo &lt;- cv.glmnet(x,y) #estimando usando LASSO e Cross Validation
  coeficientes[,i] &lt;- coef(modelo)
}

#Fim da simulação

analise &lt;- matrix(0,ncol=3,nrow=500)
colnames(analise)&lt;- c("Não zeros certos","Zeros certos", "Modelo certo?")

for(i in 1:500){
  analise[i,1]&lt;- mean(coeficientes[2:11,i] != 0)
  analise[i,2]&lt;- mean(coeficientes[12:51,i] == 0)
  analise[i,3]&lt;- ifelse(analise[i,1]+analise[i,2] == 2,1,0)
}

tabela_final &lt;- colMeans(analise)*100
knitr::kable(tabela_final,caption = "Os valores estão em porcentagem")</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-1">Table 1: </span>Os valores estão em porcentagem</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Não zeros certos</td>
<td align="right">100.00</td>
</tr>
<tr class="even">
<td align="left">Zeros certos</td>
<td align="right">83.31</td>
</tr>
<tr class="odd">
<td align="left">Modelo certo?</td>
<td align="right">0.20</td>
</tr>
</tbody>
</table>
<p>O LASSO sempre inclui as variáveis relevantes, e exclui as variáveis irrelevantes em 84% das vezes. Mesmo assim, a proporção de vezes que o LASSO consegue recuperar o modelo correto é por volta de 1%. Isso parece esquisito a primeira vista, mas lembre que recuperar o modelo certo envolve <em>acertar todas as relevantes e todas as irrelevantes</em>. Se tivermos 50 variáveis e 500 replicações e em toda replicação o LASSO colocar apenas umas variável irrelevante no modelo, nós teríamos 98% de zeros certos (<span class="math inline">\(49/50\)</span>) e exatamente 0 modelos certos.</p>
<p>Parte do problema é que o LASSO penaliza todos os coeficientes igualmente, usando o <span class="math inline">\(\lambda\)</span>. Nós esperaríamos que algumas variáveis sejam mais importantes que outras - e isso pode vir a priori ou ser dito pelos dados. O LASSO adaptativo (adaLASSO) adiciona pesos (<span class="math inline">\(\omega\)</span>) para cada uma das variáveis na penalidade. Logo o novo problema a ser resolvido é:</p>
<p><span class="math display">\[\hat{\beta}_{adaLASSO} \in \arg \min_{\beta} \displaystyle \sum_{i=1}^n (y_i - x_i \beta)^2 + \lambda \sum_{k=0}^p \frac{|\beta_k|}{\omega_k}\]</span></p>
<p>A única exigência desses pesos é que eles sejam positivos. Veja que nós temos um novo parâmetro a escolher, os pesos. Eis um algoritmo muito simples que gera os pesos baseado nos dados e usa o LASSO:</p>
<ol style="list-style-type: decimal">
<li>Estime o modelo usando LASSO. Guarde os coeficientes, que eu chamarei de <span class="math inline">\(\beta_{LASSO}\)</span></li>
<li>Defina <span class="math inline">\(\omega_k = \frac{1}{|\beta_{LASSO}|}\)</span></li>
<li>Estime o adaLASSO usando os pesos definidos em 2.</li>
</ol>
<p>A boa notícia é que o <em>glmnet</em> já nos oferece uma opção para colocar o peso, via o argumento <em>penalty.factor</em>. Nosso trabalho é basicamente reduzido a escrever umas duas linhas de código a mais: uma que faz o LASSO de “primeiro estágio” e outra que define os pesos.</p>
<p>Uma coisa deve ficar evidente: da maneira que os pesos foram estabelecidos no meu algoritmo, coeficientes que são zerados pelo LASSO serão automaticamente excluídos pelo LASSO adaptativo: teremos como peso <span class="math inline">\(1/0\)</span> (com perdão aos matemáticos), que no limite é infinito. Como o LASSO não excluiu as variáveis relevantes em nenhum caso, não vamos nos preocupar. Mas é possível imaginar situações em que o LASSO poderia ter problemas (pense em coeficientes altissimamente correlacionados em uma amostra relativamente pequena). Outra coisa que deve ficar clara é que precisamos selecionar o <span class="math inline">\(\lambda\)</span> agora duas vezes, uma para o LASSO e outra para a etapa “adaptativa” do LASSO!</p>
<p>Vamos repetir a simulação ali de cima, mas usando o adaLASSO. Em ambos os estágios eu vou usar o Cross Validation:</p>
<pre class = "line-numbers"><code class="language-r match-braces rainbow-braces">coeficientes_adalasso &lt;- Matrix(0,ncol=500,nrow=51)

for(i in 1:500){
  x &lt;- matrix(rnorm(50*100),ncol = 50) #gerando x
  betas &lt;- c(rep(1,10),rep(0,40)) #
  y &lt;- x%*%betas + rnorm(100)
  primeiro_estagio &lt;- cv.glmnet(x,y) #estimando usando LASSO e Cross Validation
  pesos &lt;- 1/abs(coef(primeiro_estagio)[-1,]) #veja que eu tenho que jogar fora o intercepto
  adalasso &lt;- cv.glmnet(x,y,penalty.factor = pesos)
  coeficientes_adalasso[,i] &lt;- coef(adalasso)
}

#Fim da simulação

analise &lt;- matrix(0,ncol=3,nrow=500)
colnames(analise)&lt;- c("Não zeros certos","Zeros certos", "Modelo certo?")

for(i in 1:500){
  analise[i,1]&lt;- mean(coeficientes_adalasso[2:11,i] != 0)
  analise[i,2]&lt;- mean(coeficientes_adalasso[12:51,i] == 0)
  analise[i,3]&lt;- ifelse(analise[i,1]+analise[i,2] == 2,1,0)
}

tabela_final &lt;- colMeans(analise)*100
knitr::kable(tabela_final,caption = "Os valores estão em porcentagem")</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-2">Table 2: </span>Os valores estão em porcentagem</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Não zeros certos</td>
<td align="right">100.00</td>
</tr>
<tr class="even">
<td align="left">Zeros certos</td>
<td align="right">96.84</td>
</tr>
<tr class="odd">
<td align="left">Modelo certo?</td>
<td align="right">58.20</td>
</tr>
</tbody>
</table>
<p>A performance do LASSO adaptativo é muito melhor que a do LASSO: em aproximadamente 60% dos casos agora recuperamos o modelo correto, contra um pouco mais de 1% dos casos para o LASSO. O adaLASSO é uma modificação extremamente simples do algoritmo do LASSO que gera excelente resultados. Veja que a escolha do Cross Validation aqui é apenas pela conveniência do glmnet já trazer o Cross Validation. Veja que implementar um critério de informação é extremamente simples. Eu vou descrever o algoritmo para o LASSO, e para o adaLASSO basta juntar os dois procedimentos:</p>
<ol style="list-style-type: decimal">
<li>Estime o modelo usando LASSO via o glmnet (não o cv.glmnet!). Isso vai devolver uma matriz de coeficientes, de dimensão <span class="math inline">\(p \times L\)</span>, onde <span class="math inline">\(L\)</span> é a quantidade de lambdas que a função usou.</li>
<li>Calcule o resíduo para cada modelo estimado <span class="math inline">\(u_l = y - X\beta_l\)</span></li>
<li>Calcule a soma do quadrado dos erros para cada modelo <span class="math inline">\(SSR = \sum_{i=1}^{n} u_i^2\)</span>.</li>
<li>Crie um vetor que tem a quantidade de coeficientes não zeros para cada modelo estimado. Vamos nos referir a cada entrada desse modelo como <span class="math inline">\(s\)</span>.</li>
<li>Calcule <span class="math inline">\(IC = n \ln(SSR) + cs\)</span> para cada modelo, onde c é o critério de informação escolhido</li>
<li>Escolha o lambda que minimiza o valor de IC</li>
</ol>
<p>Vamos escrever uma função que faz cada um dos passos. Veja que você não precisa fazer isso: existe um pacote excelente que já implementa isso no GitHub chamado <a href="https://github.com/gabrielrvsc/HDeconometrics">HDeconometrics</a>, mantido pelo Gabriel Vasconcelos. Mas seguindo o espírito do blog, eu vou implementar “no braço”. Eu vou permitir que o usuário escolha qualquer um dos 3 critérios, e para isso eu usarei uns if:</p>
<pre class = "line-numbers"><code class="language-r match-braces rainbow-braces">ic_glmnet &lt;- function(x,y,penalty.factor,ic){
  require(glmnet)
  n &lt;- length(y)
  modelo &lt;- glmnet(x,y) #passo 1
  #passo 2
  x_aux &lt;- cbind(1,x)
  u &lt;- y - x_aux%*%coef(modelo)
  #passo 3
  ssr &lt;- colSums(u^2)
  #passo 4
  conj_ativo &lt;- colSums(coef(modelo) !=0)
  #vamos permitir o usuário escolha qual critério de informação vai ser usado
  if(ic == "aic"|ic=="AIC"){
    ic_val &lt;- 2} else if(ic=="bic"|ic=="BIC"){
      ic_val &lt;- log(n)
    } else if(ic == "hqc"|ic == "HQC"){
      ic_val &lt;- 2* log(log(n))
    } else{
      stop("IC not implemented")
    }
  #passo 5
  val &lt;- n*log(ssr)+ic_val*conj_ativo
  #passo 6
  selecionado &lt;- which.min(val)
  return(list("modelo_selecionado" = coef(modelo)[,selecionado],"modelo_glmnet" = modelo, "lambda_selecionado" = modelo$lambda[selecionado]))
}</code></pre>
<p>Veja que eu faço a função retorna os coeficientes escolhidos, o modelo inteiro escolhido e o <span class="math inline">\(\lambda\)</span> escolhido ( o motivo para isso vai ficar claro). Vamos fazer um pequeno teste da nossa função:</p>
<pre class = "line-numbers"><code class="language-r match-braces rainbow-braces">x &lt;- matrix(rnorm(50*100),ncol = 50) #gerando x
betas &lt;- c(rep(1,10),rep(0,40)) #
y &lt;- x%*%betas + rnorm(100)
teste &lt;- ic_glmnet(x,y,ic="BIC")</code></pre>
<pre ><code >## Carregando pacotes exigidos: glmnet</code></pre>
<pre ><code >## Carregando pacotes exigidos: Matrix</code></pre>
<pre ><code >## Loaded glmnet 4.0-2</code></pre>
<pre class = "line-numbers"><code class="language-r match-braces rainbow-braces">teste$modelo_selecionado</code></pre>
<pre ><code >## (Intercept)          V1          V2          V3          V4          V5 
## -0.07163931  0.91825550  0.82485362  0.80345212  0.81528969  0.68988950 
##          V6          V7          V8          V9         V10         V11 
##  0.89619273  0.82549050  0.81241610  0.90796060  0.77718892  0.00000000 
##         V12         V13         V14         V15         V16         V17 
##  0.00000000  0.00000000 -0.11836918  0.00000000  0.00000000  0.00000000 
##         V18         V19         V20         V21         V22         V23 
## -0.01061692  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 
##         V24         V25         V26         V27         V28         V29 
##  0.00000000  0.00000000  0.02245120  0.00000000  0.00000000  0.00000000 
##         V30         V31         V32         V33         V34         V35 
##  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 
##         V36         V37         V38         V39         V40         V41 
##  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000 
##         V42         V43         V44         V45         V46         V47 
##  0.00000000  0.00000000  0.00000000  0.00000000  0.00000000  0.08652614 
##         V48         V49         V50 
##  0.00000000  0.00000000  0.00000000</code></pre>
<p>E uma simulação, com uma mudança: nós não vamos escolher o <span class="math inline">\(\lambda\)</span> duas vezes. Nós vamos repetir o <span class="math inline">\(\lambda\)</span> escolhido no primeiro estágio para o segundo estágio. Isso tem dois objetivos:</p>
<ol style="list-style-type: decimal">
<li>Isola o efeito da seleção do lambda dos efeitos da pessagem do LASSO adaptativo</li>
<li>Ao invés de termos de selecionar os paramêtros duas vezes, selecionamos apenas uma vez.</li>
</ol>
<p>Vamos a simulação:</p>
<pre class = "line-numbers"><code class="language-r match-braces rainbow-braces">coeficientes_adalasso_bic &lt;- Matrix(0,ncol=500,nrow=51)

for(i in 1:500){
  x &lt;- matrix(rnorm(50*100),ncol = 50) #gerando x
  betas &lt;- c(rep(1,10),rep(0,40)) #
  y &lt;- x%*%betas + rnorm(100)
  primeiro_estagio &lt;- ic_glmnet(x,y,ic = "BIC") #estimando usando LASSO e BIC
  pesos &lt;- 1/abs(primeiro_estagio$modelo_selecionado[-1]) #veja que eu tenho que jogar fora o intercepto
  adalasso &lt;- glmnet(x,y,lambda = primeiro_estagio$lambda_selecionado,penalty.factor = pesos)
  coeficientes_adalasso_bic[,i] &lt;- coef(adalasso)
}

#Fim da simulação

analise &lt;- matrix(0,ncol=3,nrow=500)
colnames(analise)&lt;- c("Não zeros certos","Zeros certos", "Modelo certo?")

for(i in 1:500){
  analise[i,1]&lt;- mean(coeficientes_adalasso_bic[2:11,i] != 0)
  analise[i,2]&lt;- mean(coeficientes_adalasso_bic[12:51,i] == 0)
  analise[i,3]&lt;- ifelse(analise[i,1]+analise[i,2] == 2,1,0)
}

tabela_final &lt;- colMeans(analise)*100
knitr::kable(tabela_final,caption = "Os valores estão em porcentagem")</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-5">Table 3: </span>Os valores estão em porcentagem</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Não zeros certos</td>
<td align="right">99.980</td>
</tr>
<tr class="even">
<td align="left">Zeros certos</td>
<td align="right">95.305</td>
</tr>
<tr class="odd">
<td align="left">Modelo certo?</td>
<td align="right">44.000</td>
</tr>
</tbody>
</table>
<p>Veja que o BIC é bastante bem sucedido em recuperar o modelo certo. Veja que como mantivemos a penalidade parada, todo o ganho vem de acertar os pesos melhor, ilustrando bem qual é o segredo do adaLASSO. Apesar disso, ele é pior do que o Cross Validation. Isso vem com duas observações, que já foram discutidas no post de Cross Validation mas eu repito aqui:</p>
<ol style="list-style-type: decimal">
<li>CV é um processo computacionalmente intensivo: quebre em blocos os seus dados, estime o modelo repetidas vezes.</li>
<li>Mais importante, Cross Validation supõe <em>independência</em> entre as observações, ou seja, não podemos usar ele para dados de séries temporais</li>
</ol>
<p>O BIC não sofre de nenhum desses problemas, o que faz dele uma alternativa atraente para selecionar modelos com LASSO adaptativo.</p>
<p>Esse é um post que aborda duas coisas: LASSO adaptativo e seleção do parâmetro de penalidade via critérios de informação. Ambos tem aplicações interessantes e não precisam ser empregadas em conjunto.</p>
<p>Mostramos como o adaLASSO é bastante superior ao LASSO em seleção de modelos. Uma pergunta justa é se a diferença de previsão dos modelos são tão diferentes assim…</p>

                        </div><div class="tags my-3"><a class="badge badge-pill badge-light border mr-2" href="/tags/lasso">
                                    <i class="fas fa-tag mr-2"></i>LASSO
                                </a></div><ul class="share nav my-3 justify-content-end">
        <li class="nav-item">
            <a class="nav-link" target="_blank" href="https://twitter.com/intent/tweet?url=https%3a%2f%2fazul.netlify.app%2f2019%2f05%2f02%2flasso-adaptativo%2f&text=LASSO%20Adaptativo%20e%20Crit%c3%a9rios%20de%20Informa%c3%a7%c3%a3o%20para%20LASSO">
              <i class="fa-fw fab fa-twitter"></i>
          </a>
        </li>
        <li class="nav-item">
            <a class="nav-link" target="_blank" href="https://www.linkedin.com/shareArticle?url=https%3a%2f%2fazul.netlify.app%2f2019%2f05%2f02%2flasso-adaptativo%2f&title=LASSO%20Adaptativo%20e%20Crit%c3%a9rios%20de%20Informa%c3%a7%c3%a3o%20para%20LASSO">
                <i class="fa-fw fab fa-linkedin-in"></i>
            </a>
        </li>
        <li class="nav-item">
            <a class="nav-link" target="_blank" href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fazul.netlify.app%2f2019%2f05%2f02%2flasso-adaptativo%2f&t=LASSO%20Adaptativo%20e%20Crit%c3%a9rios%20de%20Informa%c3%a7%c3%a3o%20para%20LASSO">
                <i class="fa-fw fab fa-facebook-f"></i>
            </a>
        </li>
        <li class="nav-item">
            <a class="nav-link" target="_blank" href="https://reddit.com/submit?url=https%3a%2f%2fazul.netlify.app%2f2019%2f05%2f02%2flasso-adaptativo%2f&title=LASSO%20Adaptativo%20e%20Crit%c3%a9rios%20de%20Informa%c3%a7%c3%a3o%20para%20LASSO">
                <i class="fa-fw fab fa-reddit-alien"></i>
            </a>
        </li>
    </nav>
                    </div>
                </div>

                <div class="row justify-content-center">
                    <div class="col-lg-8">
                        
                    </div>
                </div></article>
        </div>
    </div>

    <div class="related-content row mt-5 row-cols-1 row-cols-lg-3"><div class="col mb-3">
                <div class="card h-100">
    
    <a href="/2018/09/16/lasso/" class="d-block"><div class="card-body">
            <h4 class="card-title">O LASSO</h4>
            <p class="card-text text-muted text-uppercase">September 16, 2018</p>
            <div class="card-text">
                Este post vai tratar de um método de machine learning muito interessante e relativamente simples: o LASSO. LASSO significa Least Absolute Shrinkage and Select Operator. Como o nome sugere, o LASSO seleciona quais regressores são relevantes e quais não são. Ou seja, suponha que você é um pesquisador que tem 50 variáveis que são possíveis candidatos a variáveis explicativas de uma variável de interesse. O LASSO permite que você dê os 50 regressores para o computador e ele escolha quais são os relevantes.
            </div>
        </div>
    </a>
</div>

            </div></div>
</main>


    <footer class="footer text-center bg-dark py-6">
    <div class="container">
        <div class="row">
            <div class="col">
                <ul class="list-inline">
                    <li class="list-inline-item"><a href="https://azul.netlify.app/index.xml" rel="alternate" type="application/rss+xml" class="icons d-block">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a></li><li class="list-inline-item">
                            <a href="https://github.com/danmrc/azul/tree/master/C%C3%B3digos" class="icons d-block">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                </ul>

                <p class="text-muted">
                    
                        Copyright © 2008–2020, Pedro Cavalcante & Daniel Coutinho; all rights reserved.
                    
                </p>

                <p class="text-muted">
                Powered by <a href="https://gohugo.io" target="_blank">Hugo</a> with <a href="https://github.com/puresyntax71/hugo-theme-chunky-poster" target="_blank">Chunky Poster</a>.
                </p>
            </div>
        </div>
    </div>
</footer>

    
    
        
            <script src="/dist/main.d608eadfe5ac0688902e.min.js"></script>
        
    






<script src="/js/prism.js"></script>


    
</body>
</html>
