<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AZUL</title>
    <link>/</link>
    <description>Recent content on AZUL</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pt-br</language>
    <lastBuildDate>Fri, 19 Oct 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Testes de raiz unitária</title>
      <link>/2018/10/19/testes-de-raiz-unit%C3%A1ria/</link>
      <pubDate>Fri, 19 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/19/testes-de-raiz-unit%C3%A1ria/</guid>
      <description>Os autores deste blog foram confrontados com uma pergunta sobre o uso de testes de raiz unitária. Em linhas gerais, a pessoa já tinha passado o filtro Hodrick Prescott e o teste continuava indicando a presença de raiz unitária. Deveria este economista sentar e chorar? Ou continuar diferenciando a série?
Neste post vamos mostrar que o teste Dickey-Fuller (ADF) - padrão para testar presença de raiz unitária - tem poder baixo se (1) o processo tem uma raiz próxima de unitária e (2) a amostra é pequena.</description>
    </item>
    
    <item>
      <title>Identificação em VAR e Price Puzzle</title>
      <link>/2018/10/15/identifica%C3%A7%C3%A3o-em-var-e-price-puzzle/</link>
      <pubDate>Mon, 15 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/15/identifica%C3%A7%C3%A3o-em-var-e-price-puzzle/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Prog Dinâmica 2A</title>
      <link>/2018/10/10/prog-din%C3%A2mica-2a/</link>
      <pubDate>Wed, 10 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/10/prog-din%C3%A2mica-2a/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Prog Dinâmica IIA</title>
      <link>/2018/10/10/prog-din%C3%A2mica-2a/</link>
      <pubDate>Wed, 10 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/10/prog-din%C3%A2mica-2a/</guid>
      <description>Em um post anterior, eu falei sobre a ideia básica de programação dinâmica, e como usamos ela para resolver problemas de otimização no tempo. Naquele post, eu tratei o caso sem incerteza. Este post vai tratar do caso com incerteza.
Vamos mudar um pouco o cenário: o nosso agente continua a maximizar a utilidade, mas dessa vez ele pode investir em um ativo que paga uma taxa de juros \(r\). A incerteza vem do salário dele, que passa a ser uma variável aleatória.</description>
    </item>
    
    <item>
      <title>Identificação em VAR e Price Puzzle I</title>
      <link>/2018/10/07/identifica%C3%A7%C3%A3o-em-var-e-price-puzzle/</link>
      <pubDate>Sun, 07 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/10/07/identifica%C3%A7%C3%A3o-em-var-e-price-puzzle/</guid>
      <description>O VAR (Vector Autoregression, em inglês; em tradução livre, autoregressão vetorial) é um método padrão em estudos empíricos em macroeconomia. VARs são simplesmente empilhamentos de variáveis nas quais estimamos uma autoregressão. Para solidificar a ideia, suponha que temos duas variáveis \(x_t,y_t\) em um vetor \(\mathbb{x_t} = (x_y \phantom{0} y_t)&amp;#39;\). Um VAR seria:
\[\mathbf{x_t} = C\mathbf{x_{t-1}} + \mathbf{u_t}\]
Onde \(C\) é uma matriz \(2 \times 2\) e \(\mathbf{u_t}\) é um vetor de choques, possivelmente correlacionados.</description>
    </item>
    
    <item>
      <title>Sazonalidade, x13, e dummies: Muito barulho por nada</title>
      <link>/2018/09/24/sazonalidade-x13-e-dummies-muito-barulho-por-nada/</link>
      <pubDate>Mon, 24 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/24/sazonalidade-x13-e-dummies-muito-barulho-por-nada/</guid>
      <description>Todo mundo já enfrentou uma série temporal que tinha sazonalidade. Sempre precisamos de uma maneira de dessazonalizar. Dois métodos vem a mente: o simples use dummies para cada período, faça uma regressão e pegue os resíduos e o elaborado, quase caixa preta, x13-SEATS. Mas, faz tanta diferença qual dos dois usar?
Neste post, eu vou dessazonalizar a série de capacidade instalada da FGV usando os dois métodos - e vamos comparar as diferenças.</description>
    </item>
    
    <item>
      <title>O LASSO</title>
      <link>/2018/09/16/lasso/</link>
      <pubDate>Sun, 16 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/16/lasso/</guid>
      <description>Este post vai tratar de um método de machine learning muito interessante e relativamente simples: o LASSO. LASSO significa Least Absolute Shrinkage and Select Operator. Como o nome sugere, o LASSO seleciona quais regressores são relevantes e quais não são. Ou seja, suponha que você é um pesquisador que tem 50 variáveis que são possíveis candidatos a variáveis explicativas de uma variável de interesse. O LASSO permite que você dê os 50 regressores para o computador e ele escolha quais são os relevantes.</description>
    </item>
    
    <item>
      <title>Por que usar o Julia?</title>
      <link>/2018/09/13/por-que-usar-o-julia/</link>
      <pubDate>Thu, 13 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/13/por-que-usar-o-julia/</guid>
      <description>Eu já fiz alguns posts em que eu usava a linguagem de programação Julia. O Julia é relativamente novo: o projeto começou em 2009 e a versão 1.0 foi lançada esse ano. Apesar disso, ela já é um relativamente conhecida. O Julia promete ter uma sintaxe clara e ser mais rápido do que linguagens como o Matlab e o R.
Eu sempre tomei como certo a afirmação do Julia de que ele era mais rápido que os concorrentes.</description>
    </item>
    
    <item>
      <title>Explorando o Modelo de Solow com a ajuda do R</title>
      <link>/2018/09/11/solow/</link>
      <pubDate>Tue, 11 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/11/solow/</guid>
      <description>Em fevereiro de 1956 foi publicado no Quarterly Journal of Economics o trabalho A Contribution to the Theory of Economic Growth, de Robert Solow. Segundo o Google Scholar o paper acumulou cerca de 26000 citações de lá para cá e isso não deve ser uma grande surpresa.
Apesar de já existirem à época trabalhos importantes na área, como o de Ramsey (1928), Solow é quase um fundador da moderna teoria do crescimento econômico e por suas contribuições importantíssimas à essa literatura foi laureado com o Prêmio Nobel de Economia em 1987.</description>
    </item>
    
    <item>
      <title>Programação Dinâmica I</title>
      <link>/2018/09/08/programacao-dinamica-i/</link>
      <pubDate>Sat, 08 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/08/programacao-dinamica-i/</guid>
      <description>Este é o primeiro de uma série de posts que eu pretendo fazer sobre um tema interessante, complicado e que usa programação pesadamente - o que faz dele um carro chefe para a proposta desse blog: programação dinâmica. O nome engana: apesar de usarmos ferramentas computacionais para resolver o problema, a programação dinâmica trata de problemas de otimização no tempo. O nosso objetivo final vai ser resolver um problema de um agente otimizando a sua utilidade no tempo sem uma data final - o tempo vai para o infinito - sujeito à alguma restrição de recursos.</description>
    </item>
    
    <item>
      <title>Um pouco de microeconomia, dualidade e R</title>
      <link>/2018/09/01/microeconomia/</link>
      <pubDate>Sat, 01 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/09/01/microeconomia/</guid>
      <description>No meu segundo período da graduação em economia entrei em contato com a área que hoje me fascina, a cadeira era Teoria Micreconômica I. Ali tive um gostinho - à custa de algum sofrimento com listas e provas, confesso - do que é microeconomia. A cadeira tinha duas seções. A primeira era teoria da firma, a segunda, teoria do consumidor.
Estudamos os canônicos modelos neoclássicos de como uma firma escolhe sua planta e como um consumidor escolhe suas cestas de consumo.</description>
    </item>
    
    <item>
      <title>Interpolação</title>
      <link>/2018/08/27/interpolacao/</link>
      <pubDate>Mon, 27 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/27/interpolacao/</guid>
      <description>Este post vai discutir sobre interpolação. Não é o post mais interessante deste blog. Mas ele é necessário para posts futuros.
A ideia de interpolação é literalmente “ligar os pontos”: dado um conjunto de pontos, procuramos uma função (ou um conjunto de funções) que passe por todos os pontos. Veja que a ideia é parecida com a de Mínimos Quadrados, mas com a diferença que mínimos quadrados não necessariamente passa por todos os pontos - ou sequer passa por qualquer um dos pontos.</description>
    </item>
    
    <item>
      <title>Alguns pequenos problemas de clustering k-means</title>
      <link>/2018/08/19/problemas-clustering-k-means/</link>
      <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/19/problemas-clustering-k-means/</guid>
      <description>No meu último post mostrei como podíamos usar clustering \(k\)-means para tentar identificar - com relativo sucesso - cursos de medicina no ProUni. Hoje, ao contrário de mostrar um uso interessante de \(k\)-means, quero mostrar um problema do algoritimo relacionado a uma de suas hipoteses.
Hipoteses são ferramentas curiosas. Quem é familiarizado com economia sabe como a profissão as ama. Num geral, elas funcionam como foram concebidas: maneiras de tirar ruído e complexidade de uma questão que não são particularmente relevantes aqui.</description>
    </item>
    
    <item>
      <title>Viés de variáveis instrumentais</title>
      <link>/2018/08/19/vi%C3%A9s-de-vari%C3%A1veis-instrumentais/</link>
      <pubDate>Sun, 19 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/19/vi%C3%A9s-de-vari%C3%A1veis-instrumentais/</guid>
      <description>Como prometido no post anterior, vamos usar simulação para testar algumas coisas. A primeira delas é um problema curioso e (relativamente) pouco explorado: o viés ao usarmos muitos instrumentos em variáveis instrumentais. O excelente Mostly Harmless Econometrics, de Angrist e Pischke, conta com uma discussão sobre o tema na seção 4.6.4 - não surpreendentemente chamada de Bias of 2SLS.
Antes, uma recapitulação sobre variáveis instrumentais (se você não aprendeu sobre variáveis instrumentais, qualquer livro básico de econometria vai falar sobre o tópico): suponha que você tem o modelo \(y =x\beta+e\) e você sabe que \(E(ex) \neq 0\) - ou seja, temos um problema de endogenidade.</description>
    </item>
    
    <item>
      <title>Homens têm mais casos extraconjugais?</title>
      <link>/2018/08/17/homens-traicao/</link>
      <pubDate>Fri, 17 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/17/homens-traicao/</guid>
      <description>Você acha que homens traem mais? Eu sei que existe toda uma literatura empírica sobre o tema (ou seriam comédias românticas? nunca lembro), mas acho interessante trazer alguns dados. A fonte dos que vou usar hoje é Fair (JPE 1978), compilado no incrível manual de econometria introdutória do professor Jeffrey Wooldridge (MSU).
Vamos rodar um modelo probabilístico para ver se podemos dar nossos dois centavos nessa questão.
Probits Probits são, essencialmente, modelos lineares generalizados (GLM) em que a variável de resposta assume valores binários.</description>
    </item>
    
    <item>
      <title>Usando clustering para identificar cursos no Prouni</title>
      <link>/2018/08/11/prouni-clustering/</link>
      <pubDate>Sat, 11 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/11/prouni-clustering/</guid>
      <description>Você provavelmente conhece alguém que se formou no ensino médio e foi fazer um infame cursinho pensando em uma aprovação numa graduação em Medicina. Pois é esperado, são cursos estranhamente competitivos e com as - de longe - maiores notas de corte. Por serem tão anômalos, podem ser um exercício interessante de classificação.
Vou expor brevemente a matemática por trás do processo de Clustering k-means, alguns problemas que surgem na hora de aplicar o algoritimo e aplica-lo em uma questão interessante de economia da educação, carrer choice.</description>
    </item>
    
    <item>
      <title>Programação Dinâmica IIB</title>
      <link>/2018/08/09/programacao-dinamica-ii-b/</link>
      <pubDate>Thu, 09 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/08/09/programacao-dinamica-ii-b/</guid>
      <description>No post passado eu falei sobre programação dinâmica para o caso com tempo finito. Se você não leu, leia: o resto do post não faz sentido sem ler a primeira parte. Vamos finalmente tratar de programação dinâmica em tempo infinito. Relembrando o nosso exemplo é o caso de um consumidor que tem que escolher quanto poupar. Formalmente, queremos resolver um problema do tipo:
\[Max \sum_{t=1}^{\infty} \beta^t u(c_t) \text{ sujeito a } k_{t+1} = (1-\delta)k_t + f(k_t) - c_t \]</description>
    </item>
    
    <item>
      <title>About</title>
      <link>/about/</link>
      <pubDate>Wed, 18 Jul 2018 21:48:51 -0700</pubDate>
      
      <guid>/about/</guid>
      <description>Os Autores Este blog é mantido por Daniel Coutinho e Pedro “Cava” Cavalcante. Escrevemos sobre economia, estatística e programação, frequentemente misturando os três - é “econometria” que chama?. Ambos usam o R, uma linguagem de programação voltada para estatística, e muitos dos posts são acompanhados do código. Replicabilidade e aprender-fazendo são a serventia da casa. Sem mais delongas, eis os dois autores:
Daniel Coutinho é formado em economia pela PUC-Rio (2018) e faz mestrado em economia na mesma instituição.</description>
    </item>
    
    <item>
      <title>Monte Carlo 101</title>
      <link>/2018/07/18/monte-carlo-101/</link>
      <pubDate>Wed, 18 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/07/18/monte-carlo-101/</guid>
      <description>Simulações Monte Carlo são uma excelente maneira de entender um novo conceito, bem como explorar propriedades de estimadores. Quando queremos entender as propriedades não assintóticas dos estimadores, são raros os casos em que temos soluções analíticas: Mínimos Quadrados Ordinários é um dos casos, que parcialmente justifica a popularidade do método. Em muitos casos, usamos simulações para entender as características de um estimador em amostras finitas. Esse post tenta prover uma ilustração de como criar simulações e usa-las.</description>
    </item>
    
    <item>
      <title>print(&#34;Hello,world!&#34;)</title>
      <link>/2018/07/18/print-hello-world/</link>
      <pubDate>Wed, 18 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>/2018/07/18/print-hello-world/</guid>
      <description>Este é o primeiro post do AZUL, um blog mantido por Daniel Coutinho e Pedro “Cava” Cavalcante. Sem mais delongas, eis os dois autores:
Daniel Coutinho é formado em economia pela PUC-Rio (2018) e faz mestrado em economia na mesma instituição. É louco o suficiente para ter feito a monografia de fim de curso em econometria, e gosta de escrever sobre si próprio na terceira pessoa.
Pedro “Cava” Cavalcante é graduando em economia na UFF e estagiário de pesquisa no IPEA.</description>
    </item>
    
    <item>
      <title></title>
      <link>/1/01/01/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/1/01/01/</guid>
      <description>Usando dados da RAIS e Análise de Sobrevivência para entender desemprego        code{white-space: pre;} pre:not([class]) { background-color: white; }  if (window.hljs) { hljs.configure({languages: []}); hljs.initHighlightingOnLoad(); if (document.readyState &amp;&amp; document.readyState === &#34;complete&#34;) { window.setTimeout(function() { hljs.initHighlighting(); }, 0); } }  h1 { font-size: 34px; } h1.title { font-size: 38px; } h2 { font-size: 30px; } h3 { font-size: 24px; } h4 { font-size: 18px; } h5 { font-size: 16px; } h6 { font-size: 12px; } .</description>
    </item>
    
  </channel>
</rss>