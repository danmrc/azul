<!DOCTYPE html>
<html lang="pt-br">
	<head>
		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		
		<meta name="author" content="Daniel Coutinho e Pedro Cavalcante">
		<meta name="description" content="Economia, Estatística, Programação">
		<meta name="generator" content="Hugo 0.49" />
		<title>Amostrando de distribuições difíceis: o Markov Chain Monte Carlo &middot; AZUL</title>
		<link rel="shortcut icon" href="/images/favicon.ico">
		<link rel="stylesheet" href="/css/style.css">
		<link rel="stylesheet" href="/css/highlight.css">

		
		<link rel="stylesheet" href="/css/monosocialiconsfont.css">
		

		

		
	</head>

    <body>
       <nav class="main-nav">
	
	
		<a href='/'> <span class="arrow">←</span>Início</a>
	
	<a href='/post'>Arquivo</a>
	<a href='/tags'>Tags</a>
	<a href='/about'>Sobre</a>
  <a href='/categories'>Categorias</a>
  
	

	
</nav>


        <section id="wrapper" class="post">
            <article>
                <header>
                    <h1>
                        Amostrando de distribuições difíceis: o Markov Chain Monte Carlo
                    </h1>
                    <h3> Daniel Coutinho </h3>
                    <h2 class="headline">
                    Feb 8, 2020 00:00
                    · 2292 words
                    · 11 minute read
                      <span class="tags">
                      
                      
                          
                              <a href="/tags/monte-carlo">Monte Carlo</a>
                          
                              <a href="/tags/markov-chain-monte-carlo">Markov Chain Monte Carlo</a>
                          
                              <a href="/tags/bayesiana">Bayesiana</a>
                          
                      
                      
                      </span>
                    </h2>
                </header>
                
                  
                
                <section id="post-body">
                    <script src="2020-01-23-amostrando-de-distribuições-difíceis-o-markov-chain-monte-carlo_files/jquery/jquery.min.js"></script>
<script src="2020-01-23-amostrando-de-distribuições-difíceis-o-markov-chain-monte-carlo_files/elevate-section-attrs/elevate-section-attrs.js"></script>


<p>Eu recentemente tive a chance de brincar com o Markov Chain Monte Carlo (MCMC daqui por diante) no contexto de DSGE - e quando eu digo brincar eu não quero dizer que usei o Dynare, por sinal. O algoritmo é bastante esperto e funciona surpreendentemente bem. Eu não vou me atrever a entrar nos detalhes de <em>porque</em> funciona, mas eu vou descrever o algoritmo com algum detalhe e mostrar um exemplozinhho de regressão Bayesiana.</p>
<p>O algoritmo tem várias etapas e vai requerer que a gente tenha (a) uma distribuição alvo e (b) um <em>kernel</em>. A ideia é que é difícil retirar números aleatórios da distribuição alvo e nós queremos obter esses números por algum motivo. No caso bayesiano, eles querem obter a distribuição do parâmetro dada a regra de Bayes. Vamos temporariamente fingir que somos bayesianos. Seja <span class="math inline">\(x\)</span> os dados e <span class="math inline">\(\theta\)</span> os parâmetros, portanto queremos a <em>posterior</em>:</p>
<p><span class="math display">\[p(\theta|x) = \frac{p(\theta)\ell(x|\theta)}{p(x)}\]</span></p>
<p>Onde <span class="math inline">\(p(\theta)\)</span> é a <em>prior</em> do parâmetro - a distribuição que específica a crença do pesquisador antes de ver os dados - <span class="math inline">\(\ell(x|\theta)\)</span> é a verossimelhança e <span class="math inline">\(p(x)\)</span> é a distribuição de x. Veja que os dois primeiros elementos são fáceis de especificar; <span class="math inline">\(p(x)\)</span> requer a distribuição de x marginalizando para o parâmetro, o que pode ser impossível de obter - se temos dez parâmetros isso requer dez integrais e nós passamos a sofrer da maldição da dimensionalidade.</p>
<p>Existem vários algoritmos que sorteiam de distribuições potencialmente difíceis de serem amostradas, e eu vou discutir um deles neste post. Mas todos basicamente partem da mesma ideia: sorteie números aleatórios de alguma distribuição que a gente sabe sortear. Use a densidade da distribuição que queremos de fato obter uma amostra para decidir se o parâmetro sorteado deve ser aceito ou não. Se quisermos uma estatística específica da distribuição - média, moda, mediana, desvio padrão - basta calcular a estatística empírica a partir da amostra e deixar a Lei dos Grandes Números agir.</p>
<p>A primeira sacada esperta é notar que, dado duas propostas de parâmetros, <span class="math inline">\(\theta\)</span> e <span class="math inline">\(\theta^{\prime}\)</span>, <span class="math inline">\(p(\theta^\prime|x)/p(\theta|x)\)</span>, podemos cancelar o <span class="math inline">\(p(x)\)</span> fora. Assim, se conseguirmos uma maneira de amostrar a distribuição usando a razão, nos livramos da integral.</p>
<p>A segunda sacada é notar que, já que estamos usando uma razão, podemos usar o fato que se migrarmos de um ponto de menor probabilidade na <em>posterior</em> para um de maior probabilidade, então a razão será maior que 1.</p>
<p>A terceira sacada é que se a gente rejeitar toda vez que a <em>posterior</em> diminuir, nós teremos dois problemas:</p>
<ol style="list-style-type: decimal">
<li><p>Naturalmente o algoritmo vai convergir para o máximo e ficar preso lá</p></li>
<li><p>Pior, ele pode convergir para um máximo local e ficar preso lá.</p></li>
</ol>
<p>Para entender o segundo ponto, dê uma olhada na seguinte função:</p>
<pre class="r"><code>xx &lt;- seq(-2,2,by = 0.05)
yy &lt;- dnorm(xx,mean = -1,sd = 0.7) + dnorm(xx,mean=1, sd = 0.5)

plot(xx,yy, type = &quot;l&quot;, 
     xlab = &quot; &quot;, 
     ylab = &quot; &quot;)

dm1 &lt;- dnorm(-1, mean = -1, sd = 0.7)
d1 &lt;- dnorm(1, mean = 1, sd = 0.5)
d0 &lt;- dnorm(0,mean = 1, sd = 0.5) + dnorm(0, mean = -1, sd = 0.7) 

points(-1, dm1, pch = 17, col = 2, cex = 2)
points(1, d1, pch = 17,col = 4, cex = 2)
points(0, d0, pch = 17,col = 3, cex = 2)

arrows(x0 = -1, y0 = dm1, x1 = 0, y1 = d0, lty = 2, lwd = 2)
arrows(x0 = 0, y0 = d0, x1 = 1, y1 = d1, lty = 2, lwd = 2)</code></pre>
<p><img src="/post/2020-01-23-amostrando-de-distribui%C3%A7%C3%B5es-dif%C3%ADceis-o-markov-chain-monte-carlo_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>Se começamos no triângulo vermelho, qualquer ponto ao redor reduz a densidade. Mas veja que o triângulo vermelho é um máximo local e o triângulo azul o máximo global. Nós potencialmente gostaríamos de aceitar até mesmo o ponto verde se nós fizermos o caminho indicado pelas setas. Obviamente, dificilmente teremos uma situação tão evidente como essa, mas é bastante ilustrativo.</p>
<p>Então nós não queremos rejeitar um ponto potencial só porque ele reduz a <em>posterior</em> - queremos aceitar ele, de vez em quando. A ideia aqui é aceitar ele com maior probabilidade quanto mais próxima de 1 for a razão <span class="math inline">\(p(\theta^\prime|x)/p(\theta|x)\)</span>.</p>
<p>Espero ter convencido o leitor que é útil trabalhar com a razão <span class="math inline">\(p(\theta^\prime|x)/p(\theta|x)\)</span> para <em>aceitar ou rejeitar</em> um valor como representativo da distribuição. Mas ainda não atacamos o problema fundamental de <em>como</em> escolher esse valor. O procedimento é bem simples: escolha a distribuição <em>kernel</em> e sorteie um valor dela. Esse vai ser o valor que a ser testado.</p>
<p>A distribuição <em>kernel</em> tem que ser espertamente escolhida, porque existem várias condições sobre o <em>kernel</em> para garantir que a distribuição do algoritmo é a distribuição alvo. Para todos os efeitos, a normal centrada no último valor aceito é perfeito para os própositos - a escolha da variância é muito importante e eu vou discutir abaixo. Usar a distribuição centrada no último valor aceito gera o algoritmo chamado <em>Random Walk Metropolis Hasting</em> - a parte do Random Walk se deve ao fato da distribuição do sorteio ser centrado no último valor aceito.</p>
<p>Nós também vamos querer corrigir a probabilidade de aceitação e rejeição pelo <em>kernel</em>. A intuição é que não só importa o quão provável é o novo parâmetro dado a posterior, mas o quão provável é o parâmetro dado o <em>kernel</em>: se nós sorteamos um parâmetro na ponta do kernel isso tem que ser levado em conta. Uma explicação um pouco mais séria: o importante é que a probabilidade de passar do ponto x para o ponto y seja igual. Uma distribuição qualquer não garante isso, mas corrigir a razão pelo kernel faz com que isso seja satisfeito. Isso não significa que qualquer distribuição serve como <em>Kernel</em>. Então, seja <span class="math inline">\(\mathcal{K}(\theta^\prime|\theta)\)</span> a probabilidade de passar do ponto <span class="math inline">\(\theta\)</span> para <span class="math inline">\(\theta^\prime\)</span>. A razão que vamos nos preocupar é:</p>
<p><span class="math display">\[\frac{p(\theta^\prime|x)\mathcal{K}(\theta^\prime|\theta)}{p(\theta|x)\mathcal{K}(\theta|\theta^\prime)}\]</span></p>
<p>Veja que se o kernel faz com que a probabilidade de passar do ponto x para o ponto y é igual a de passar do ponto y para o ponto x, então <span class="math inline">\(\mathcal{K}(\theta^\prime|\theta)\)</span> = <span class="math inline">\(\mathcal{K}(\theta|\theta^\prime)\)</span>, os termos se cancelam e voltamos a nossa razão que eu coloquei no começo.</p>
<p>Eu escrevi bastante coisa e parece justo fazer um resumo do passo a passo do discutido até aqui:</p>
<p>Defina a função <em>kernel</em>, a <em>posterior</em> (que depende da verossimelhança e das <em>priors</em>) e um ponto inicial do espaço paramétrico, <span class="math inline">\(\theta\)</span></p>
<ol style="list-style-type: decimal">
<li>Sorteie um possível valor possível do parâmetro da distribuição <em>kernel</em>. Chame esse valor de <span class="math inline">\(\theta^\prime\)</span></li>
<li>Compute <span class="math inline">\(r = \max \left(1,\frac{p(\theta^\prime|x)\mathcal{K}(\theta^\prime|\theta)}{p(\theta|x)\mathcal{K}(\theta|\theta^\prime)}\right)\)</span></li>
<li>Sorteie u ~ Uniforme(0,1)</li>
<li>Se <span class="math inline">\(r &gt; u\)</span>, aceite e <span class="math inline">\(\theta = \theta^\prime\)</span>. Caso contrário, rejeite e <span class="math inline">\(\theta = \theta\)</span></li>
<li>Itere n vezes</li>
</ol>
<p>Veja que se o parâmetro for rejeitado, <em>o valor antigo vai ser repetido</em> na simulação. Isso vai garantir com que pontos de alta probabilidade apareçam mais na distribuição empírica, e portanto tenha probabilidade empírica maior.</p>
<div id="um-exemplo" class="section level1">
<h1>Um exemplo</h1>
<p>Como de praxe, um exemplo vai ajudar muito a entender tudo que eu escrevi. Vamos fazer uma situação super simples onde eu tenho uma regressão <span class="math inline">\(y = \beta{}x + \varepsilon\)</span> e <span class="math inline">\(\beta = 1.5\)</span>, 100 observações e <span class="math inline">\(\varepsilon \sim N(0,1)\)</span></p>
<pre class="r"><code>x &lt;- rnorm(100)
y &lt;- 1.5*x + rnorm(100)</code></pre>
<p>Vamos fazer a função de verossimelhança. Como o erro é normal, então <span class="math inline">\(y|x \sim N(\beta{}x,1)\)</span>. Eu vou escrever direto a <em>log</em> verossimelhança</p>
<pre class="r"><code>loglike &lt;- function(y,x,beta){
  sum(dnorm(y-beta*x,log = T))
}</code></pre>
<p>Para a prior, eu vou colocar uma Normal de média 0 e desvio padrão 3, e com isso temos a posterior:</p>
<pre class="r"><code>posterior &lt;- function(y,x,beta){
  loglike(y,x,beta) + dnorm(beta,mean=0,sd=3,log = T)
}</code></pre>
<p>Note que como eu estou trabalhando com o log de tudo, ao invés de multiplicar a verossimelhança pela prior, eu somo as duas. Há bons motivos para trabalhar com a soma ao invés de multiplicação: <em>thou shall not multiply two small numbers</em> é um dos mandamentos de computação numérica (juro que escrevo um post curtinho sobre ponto flutuante!).</p>
<p>Agora sim podemos passar para o MCMC. Eu vou fazer 5000 passos e iniciar em zero:</p>
<pre class="r"><code>set.seed(19965)

n &lt;- 10000

params_mcmc &lt;- rep(0,n)

for(i in 2:n){
  par_novo &lt;- rnorm(1,mean = params_mcmc[i-1], sd = 0.5)
  kernel_velho &lt;- dnorm(par_novo,mean = params_mcmc[i-1], sd = 0.5, log = T)
  kernel_novo &lt;- dnorm(params_mcmc[i-1],mean = par_novo, sd = 0.5, log = T)
  r_denom &lt;- posterior(y,x,par_novo) + kernel_novo
  r_nomi &lt;- posterior(y,x,params_mcmc[i-1]) + kernel_velho
  r &lt;- r_denom - r_nomi
  u &lt;- runif(1)
  r &lt;- max(exp(r),0)
  if(r &gt; u){
    params_mcmc[i] &lt;- par_novo
  } else{
    params_mcmc[i] &lt;- params_mcmc[i-1]
  }
}</code></pre>
<p>Usualmente, demora algum tempo até a cadeia de markov convergir para a distribuição que queremos - isso depende uma série de coisas, como o quão perto é o nosso chute inicial da moda e a complexidade do modelo. Em geral, se descarta algumas observações iniciais enquanto a cadeia ainda está convergindo, que é chamado <em>burn-in</em>. Eu vou jogar as 4 mil primeiras fora e ver o histograma da distribuição:</p>
<pre class="r"><code>library(ggplot2) 

pars &lt;- params_mcmc[4001:10000]

ggplot(data.frame(pars = pars),aes(pars)) + geom_histogram(bins = 30) + scale_x_continuous(breaks = seq(1,2,by = 0.1)) + theme_bw() </code></pre>
<p><img src="/post/2020-01-23-amostrando-de-distribui%C3%A7%C3%B5es-dif%C3%ADceis-o-markov-chain-monte-carlo_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>Veja que o histograma não é muito suave e nem está centrado no valor verdadeiro do parâmetro. Temos vários possíveis suspeitos, mas eu imagino que o problema seja que nós temos apenas 100 observações. Observe que se rodarmos o bom e velho Mínimos Quadrados, obtemos o coeficiente 1.3973191 - próximo da moda do histograma. Vamos aumentar o tamanho da amostra e repetir o MCMC:</p>
<pre class="r"><code>x &lt;- rnorm(1000)
y &lt;- 1.5*x + rnorm(1000)

n &lt;- 10000

params_mcmc &lt;- rep(0,n)
aceitacao &lt;- 0

for(i in 2:n){
  par_novo &lt;- rnorm(1,mean = params_mcmc[i-1], sd = 0.5)
  kernel_velho &lt;- dnorm(par_novo,mean = params_mcmc[i-1], sd = 0.5, log = T)
  kernel_novo &lt;- dnorm(params_mcmc[i-1],mean = par_novo, sd = 0.5, log = T)
  r_denom &lt;- posterior(y,x,par_novo) + kernel_novo
  r_nomi &lt;- posterior(y,x,params_mcmc[i-1]) + kernel_velho
  r &lt;- r_denom - r_nomi
  u &lt;- runif(1)
  r &lt;- max(exp(r),0)
  if(r &gt; u){
    params_mcmc[i] &lt;- par_novo
    aceitacao &lt;- aceitacao + 1 #continue lendo, isso vai ficar claro
  } else{
    params_mcmc[i] &lt;- params_mcmc[i-1]
  }
}

pars &lt;- params_mcmc[4000:10000]

ggplot(data.frame(pars = pars),aes(pars)) + geom_histogram(bins = 30) + scale_x_continuous(breaks = seq(1,2,by = 0.05)) + theme_bw() </code></pre>
<p><img src="/post/2020-01-23-amostrando-de-distribui%C3%A7%C3%B5es-dif%C3%ADceis-o-markov-chain-monte-carlo_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>Agora o histograma nos mostra bem perto de 1.5!</p>
<p>Veja que eu falei que a variância do Kernel é bem importante. Em geral, a variância é escolhida de maneira que a aceitação fique perto dos 20% - esse é o valor ótimo de aceitação para o MCMC. Eu ignorei totalmente esse fato por enquanto, mas observe que eu salvei uma variável que nos dá a taxa de aceitação: é a variável <code>aceitacao</code>(duh); basta dividir ela pelo total de simulações (<code>n</code>) e teremos nossa taxa de aceitação. No caso, ela é 8.16%. Vamos aumentar a variância e ver o que acontece:</p>
<pre class="r"><code>x &lt;- rnorm(1000)
y &lt;- 1.5*x + rnorm(1000)

n &lt;- 10000

params_mcmc &lt;- rep(0,n)
aceitacao &lt;- 0

for(i in 2:n){
  par_novo &lt;- rnorm(1,mean = params_mcmc[i-1], sd = 1.5)
  kernel_velho &lt;- dnorm(par_novo,mean = params_mcmc[i-1], sd = 1.5, log = T)
  kernel_novo &lt;- dnorm(params_mcmc[i-1],mean = par_novo, sd = 1.5, log = T)
  r_denom &lt;- posterior(y,x,par_novo) + kernel_novo
  r_nomi &lt;- posterior(y,x,params_mcmc[i-1]) + kernel_velho
  r &lt;- r_denom - r_nomi
  u &lt;- runif(1)
  r &lt;- max(exp(r),0)
  if(r &gt; u){
    params_mcmc[i] &lt;- par_novo
    aceitacao &lt;- aceitacao + 1
  } else{
    params_mcmc[i] &lt;- params_mcmc[i-1]
  }
}

pars &lt;- params_mcmc[2000:10000]


ggplot(data.frame(pars = pars),aes(pars)) + geom_histogram(bins = 30) + scale_x_continuous(breaks = seq(1,2,by = 0.05)) + theme_bw() </code></pre>
<p><img src="/post/2020-01-23-amostrando-de-distribui%C3%A7%C3%B5es-dif%C3%ADceis-o-markov-chain-monte-carlo_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>A taxa de aceitação agora é 3.39%. variância muito alta faz a distribuição ficar esquisita. A intuição é simples: como é um passeio aleatório, a distribuição vai passear por uma região muito maior, possivelmente visitando pontos com uma probabilidade muito baixa de ser aceita.</p>
<p>Podemos ter o problema oposto: a variância ser muito baixa e o algoritmo demorar um tempo enorme para visitar a distribuição:</p>
<pre class="r"><code>x &lt;- rnorm(1000)
y &lt;- 1.5*x + rnorm(1000)

n &lt;- 10000

params_mcmc &lt;- rep(0,n)
aceitacao &lt;- 0

for(i in 2:n){
  par_novo &lt;- rnorm(1,mean = params_mcmc[i-1], sd = 1e-8)
  kernel_velho &lt;- dnorm(par_novo,mean = params_mcmc[i-1], sd = 1e-8, log = T)
  kernel_novo &lt;- dnorm(params_mcmc[i-1],mean = par_novo, sd = 1e-8, log = T)
  r_denom &lt;- posterior(y,x,par_novo) + kernel_novo
  r_nomi &lt;- posterior(y,x,params_mcmc[i-1]) + kernel_velho
  r &lt;- r_denom - r_nomi
  u &lt;- runif(1)
  r &lt;- max(exp(r),0)
  if(r &gt; u){
    params_mcmc[i] &lt;- par_novo
    aceitacao &lt;- aceitacao + 1
  } else{
    params_mcmc[i] &lt;- params_mcmc[i-1]
  }
}

pars &lt;- params_mcmc[2000:10000]


ggplot(data.frame(pars = pars),aes(pars)) + geom_histogram(bins = 30) + theme_bw() </code></pre>
<p><img src="/post/2020-01-23-amostrando-de-distribui%C3%A7%C3%B5es-dif%C3%ADceis-o-markov-chain-monte-carlo_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<p>Na prática, como colocamos 10 mil passos, a distribuição fica uma bagunça perto de zero. Ou seja, errar a variância tem efeitos perturbadores no algoritmo. A taxa de aceitação é 99.99%.</p>
<p>Veja que isso sugere que se nós estivermos aceitando demais, nós devemos <em>aumentar</em> a variância do <em>kernel</em>; e se tivermos aceitando de menos devemos diminuir a variância.</p>
<p>Isso ilustra como MCMC funciona. Longe de ser uma caixa preta, é um algoritmo relativamente simples, fácil de implementar. A taxa de aceitação ótima e o tamanho do <em>burn-in</em> são problemáticos, com modelos grandes exigindo um milhão de passos e quase a metade sendo descartados (!). Ainda temos um parâmetro para escolher, a variância do <em>Kernel</em>. Veja que ainda temos uma limitação que eu nem toquei: como a distribuição é Normal, os parâmetros devem ser definidos nos Reais. É comum em modelos, inclusive modelos DSGE, definir um pedaço dos reais para os parâmetros - a taxa de desconto intertemporal está entra 0 e 1, por exemplo. Nesse caso, temos que fazer transformações nos parâmetros e alterar a distribuição via o jacobiano… um pouco mais confuso! Mas os fundamentos não mudam.</p>
<p>A ideia de passear aleatoriamente pelo espaço paramétrico não é tão brilhante quando temos uma dimensão muito alta: é como tentar procurar a chave perdida andando por ai e torcendo para topar com ela em algum momento. Os usuários de métodos de MCMC se deram conta disso e desenvolveram métodos que ao invés de usar um passeio aleatório passeiam pelo espaço paramétrico de maneira um pouco mais esperta…</p>
<p>Um excelente livro sobre MCMC e algoritmos correlatos é o <em>Bayesian Data Analysis</em>, de Andrew Gelman e (muitos) coautores.</p>
</div>

                </section>
            </article>

            
                <a class="twitter" href="https://twitter.com/intent/tweet?text=%2f2020%2f02%2f08%2fmarkov-chain-monte-carlo%2f - Amostrando%20de%20distribui%c3%a7%c3%b5es%20dif%c3%adceis%3a%20o%20Markov%20Chain%20Monte%20Carlo "><span class="icon-twitter"> tweet</span></a>

<a class="facebook" href="#" onclick="
    window.open(
      'https://www.facebook.com/sharer/sharer.php?u='+encodeURIComponent(location.href),
      'facebook-share-dialog',
      'width=626,height=436');
    return false;"><span class="icon-facebook-rect"> Share</span>
</a>

            

            

            

            <footer id="footer">
    
        <div id="social">

	
	
    
    <a class="symbol" href="https://github.com/danmrc/azul/tree/master/C%C3%B3digos">
        github
    </a>
    


</div>

    
    <p class="small">
    
       © Copyright 2020 <i class="fa fa-heart" aria-hidden="true"></i> Daniel Coutinho e Pedro Cavalcante
    
    </p>
    <p class="small">
        Powered by <a href="http://www.gohugo.io/">Hugo</a> Theme By <a href="https://github.com/nodejh/hugo-theme-cactus-plus">nodejh</a>
    </p>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.css" integrity="sha384-9eLZqc9ds8eNjO3TmqPeYcDj8n+Qfa4nuSiGYa6DjLNcv9BtN69ZIulL9+8CqC9Y" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/katex.min.js" integrity="sha384-K3vbOmF2BtaVai+Qk37uypf7VrgBubhQreNQe9aGsz9lB63dIFiQVlJbr92dw2Lx" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/contrib/auto-render.min.js" integrity="sha384-kmZOZB5ObwgQnS/DuDg6TScgOiWWBiVt0plIRkZCmE6rDZGrEOQeHM5PcHi+nyqe" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
</footer>

        </section>

        <script src="/js/jquery-3.3.1.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>




  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-123754589-1', 'auto');
	
	ga('send', 'pageview');
}
</script>





    </body>
</html>
