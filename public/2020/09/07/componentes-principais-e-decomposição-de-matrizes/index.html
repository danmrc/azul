<!DOCTYPE html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<title>
  
     Componentes Principais e decomposição de matrizes | 
    AZUL
  
</title><meta name="description" content="Economia, Estatística, Programação"><meta name="author" content="danielc">

<link rel="apple-touch-icon" href="/apple-touch-icon.png" sizes="180x180">
<link rel="icon" href="/favicon-32x32.png " sizes="32x32" type="image/png">
<link rel="icon" href="/favicon-16x16.png" sizes="16x16" type="image/png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#0c344b">
<link rel="icon" href="/favicon.ico">

//styles, look here: https://cdnjs.com/libraries/highlight.js/9.12.0

<link href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/vs2015.min.css" rel="stylesheet">





    
        
            <link rel="stylesheet" href="/dist/main.37ab3f61b95417873748.min.css">
        
    




<link rel="canonical" href="/2020/09/07/componentes-principais-e-decomposi%C3%A7%C3%A3o-de-matrizes/"><meta property="og:title" content="Componentes Principais e decomposição de matrizes" />
<meta property="og:description" content="Em geral muitas coisas de Machine Learning são apenas truques de Algébra Linear. Isso nem sempre é explorado o suficiente, e então álgebra linear parece um mundo de abstrações em espaços vetoriais. No caso de Componentes Principais, o método se resume a Álgebra Linear, como eu pretendo explorar nesse post.
Componentes Principais Eu vou trabalhar no \(\mathbb{R}^2\) pra facilitar. A ideia de encontrar componentes principais é encontrar uma rotação dos dados que resuma melhor a variação deles em menos variáveis." />
<meta property="og:type" content="article" />
<meta property="og:url" content="/2020/09/07/componentes-principais-e-decomposi%C3%A7%C3%A3o-de-matrizes/" />
<meta property="article:published_time" content="2020-09-07T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-09-07T00:00:00+00:00" />
<meta itemprop="name" content="Componentes Principais e decomposição de matrizes">
<meta itemprop="description" content="Em geral muitas coisas de Machine Learning são apenas truques de Algébra Linear. Isso nem sempre é explorado o suficiente, e então álgebra linear parece um mundo de abstrações em espaços vetoriais. No caso de Componentes Principais, o método se resume a Álgebra Linear, como eu pretendo explorar nesse post.
Componentes Principais Eu vou trabalhar no \(\mathbb{R}^2\) pra facilitar. A ideia de encontrar componentes principais é encontrar uma rotação dos dados que resuma melhor a variação deles em menos variáveis.">
<meta itemprop="datePublished" content="2020-09-07T00:00:00+00:00" />
<meta itemprop="dateModified" content="2020-09-07T00:00:00+00:00" />
<meta itemprop="wordCount" content="1048">



<meta itemprop="keywords" content="Componentes Principais,Álgebra Linear,SVD,Autovalores," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Componentes Principais e decomposição de matrizes"/>
<meta name="twitter:description" content="Em geral muitas coisas de Machine Learning são apenas truques de Algébra Linear. Isso nem sempre é explorado o suficiente, e então álgebra linear parece um mundo de abstrações em espaços vetoriais. No caso de Componentes Principais, o método se resume a Álgebra Linear, como eu pretendo explorar nesse post.
Componentes Principais Eu vou trabalhar no \(\mathbb{R}^2\) pra facilitar. A ideia de encontrar componentes principais é encontrar uma rotação dos dados que resuma melhor a variação deles em menos variáveis."/>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>



</head>
<body>
    
<nav class="navbar navbar-expand-md navbar-light bg-light fixed-top shadow-sm" id="navbar-main-menu">
    <div class="container">
        <a class="navbar-brand font-weight-bold" href="/">AZUL</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#main-menu" aria-controls="main-menu" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="main-menu">
            <ul class="navbar-nav ml-auto">
                
                    <li class="nav-item"><a class="nav-link" href="/">Home</a></li>
                
                    <li class="nav-item"><a class="nav-link" href="/categories/">Categorias</a></li>
                
                    <li class="nav-item"><a class="nav-link" href="/about/">Sobre</a></li>
                
                    <li class="nav-item"><a class="nav-link" href="/tags/">Tags</a></li>
                
            
            </ul>
        </div>
    </div>
</nav>


    
<main class="content-page container pt-7 pb-5">
    
    <div class="row">
        <div class="col">
            <article>
                <div class="row justify-content-center">
                    <div class="col-lg-8">
                        <div class="meta text-muted mb-3">
                            <p class="created text-muted text-uppercase font-weight-bold mb-1">September 7, 2020</p>
                            <span class="mr-2"><i class="fas fa-book-open mr-2"></i>1048 palavras</span>
                            <span><i class="fas fa-clock mr-2"></i>5 mins</span>
                        </div>

                        <h1>Componentes Principais e decomposição de matrizes</h1>

                        <ul class="authors list-inline"><li class="list-inline-item mr-3">
                    <div class="media author"><div class="media-body">
                            <h5 class="name my-0"><a href="/authors/danielc/" class="small">Daniel Coutinho</a>
                            </h5></div>
                    </div>
                </li></ul>
                    </div>
                </div><div class="row justify-content-center">
                    <div class="col-lg-8">
                        <div class="content">
                            
<script src="2020-08-30-componentes-principais-e-decomposição-de-matrizes_files/header-attrs/header-attrs.js"></script>


<p>Em geral muitas coisas de Machine Learning são apenas truques de Algébra Linear. Isso nem sempre é explorado o suficiente, e então álgebra linear parece um mundo de abstrações em espaços vetoriais. No caso de Componentes Principais, o método se resume a Álgebra Linear, como eu pretendo explorar nesse post.</p>
<div id="componentes-principais" class="section level2">
<h2>Componentes Principais</h2>
<p>Eu vou trabalhar no <span class="math inline">\(\mathbb{R}^2\)</span> pra facilitar. A ideia de encontrar componentes principais é encontrar uma rotação dos dados que resuma melhor a variação deles em menos variáveis. Veja que <span class="math inline">\(\mathbb{R}^2\)</span> é extremamente infeliz para isso - afinal qual a graça de resumir <em>duas</em> variáveis. Mas a visualização fica bem mais fácil.</p>
<p>Eu vou gerar uma amostra aleatória da normal bivariada, com variância 1, correlação 0.7 e média zero e plottar isso:</p>
<pre class="r"><code>library(MASS)
library(ggplot2)

S &lt;- cbind(c(1,.7),c(.7,1))
ams &lt;- mvrnorm(n=100,mu = c(0,0),Sigma=S)
df &lt;- data.frame(ams)
ggplot(df,aes(X1,X2)) + geom_point()</code></pre>
<p><img src="/post/2020-08-30-componentes-principais-e-decomposi%C3%A7%C3%A3o-de-matrizes_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<p>Veja que se eu traçar uma reta na diagonal e uma reta ortogonal a ela, eu vou ter um novo sistema de coordenadas no qual um dos eixos está na direção que tem o máximo de variação:</p>
<pre class="r"><code>ggplot(df,aes(X1,X2)) + geom_point() + geom_abline(slope=1,intercept=0)</code></pre>
<p><img src="/post/2020-08-30-componentes-principais-e-decomposi%C3%A7%C3%A3o-de-matrizes_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>ggplot(df,aes(X1,X2)) + geom_point() + geom_abline(slope=1,intercept=0) + geom_abline(slope=-1,intercept=0)</code></pre>
<p><img src="/post/2020-08-30-componentes-principais-e-decomposi%C3%A7%C3%A3o-de-matrizes_files/figure-html/unnamed-chunk-2-2.png" width="672" /></p>
<p>O segundo gráfico só coloca um segundo eixo. Formalizar isso requer o uso de um velho conhecido nosso, os autovalores.</p>
</div>
<div id="componentes-principais-são-autovetores" class="section level2">
<h2>Componentes Principais são autovetores</h2>
<p>Como eu quero o máximo de variação, faz sentido começar pensando na matriz de variância, <span class="math inline">\(\Sigma\)</span>. Como <span class="math inline">\(\Sigma\)</span> é uma matriz simétrica, positiva definida, nós sabemos que os autovetores formam uma base ortogonal e os autovalores são positivos. Eu vou fazer a decomposição em autovalores da matriz de variância, S, e plotar o autovetor associado ao maior autovalor:</p>
<pre class="r"><code>auto &lt;- eigen(S)$vectors

ggplot(df,aes(X1,X2)) + geom_point() + geom_segment(x=0,y=0, yend=auto[2,1],xend=auto[1,1],arrow=arrow())</code></pre>
<p><img src="/post/2020-08-30-componentes-principais-e-decomposi%C3%A7%C3%A3o-de-matrizes_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<p>O autovetor aponta exatamente na direção que a gente quer. Vamos entender a matemática: seja <span class="math inline">\(x\)</span> o vetor de variáveis aleatórias. Nós queremos encontrar um vetor <span class="math inline">\(\omega\)</span> que faça com que <span class="math inline">\(\omega^{\prime}x\)</span> gere a maior variância possível, ou seja <span class="math inline">\(\max_\omega \omega xx^{\prime} \omega^{\prime}\)</span>. Veja que sem uma normalização em <span class="math inline">\(\omega\)</span>, qualquer múltiplo vai resolver o problema. Posto de outra forma (100% roubada), se <span class="math inline">\(\omega\)</span> é um autovetor, então qualquer múltiplo dele também é. Pra facilitar as contas, vamos estabelecer que <span class="math inline">\(\omega^{\prime}\omega = 1\)</span>. Eu poderia resolver usando multiplicador de Lagrange, mas deixa eu fazer algo menos estruturado: comece pela função objetivo do problema de maximização, sabendo que <span class="math inline">\(xx^{\prime} = \Sigma\)</span>:</p>
<p><span class="math display">\[\omega^{\prime} \Sigma \omega\]</span></p>
<p>Eu já disse que <span class="math inline">\(\Sigma\)</span> admite uma representação por autovetores que formam uma base ortogonal, então se <span class="math inline">\(P\)</span> é a matriz de autovetores, e por ser ortogonal, <span class="math inline">\(P&#39; = P^{-1}\)</span>. A matriz de autovalores (que é diagonal) vai ser <span class="math inline">\(\Lambda\)</span>:</p>
<p><span class="math display">\[\omega^{\prime} \Sigma \omega = \omega^{\prime} P^{\prime}\Lambda{}P \omega\]</span></p>
<p>Agora defina <span class="math inline">\(\omega{}P = y\)</span> e teremos:</p>
<p><span class="math display">\[\omega^{\prime} \Sigma \omega = \omega^{\prime} P^{\prime}\Lambda{}P \omega = y^{\prime} \Lambda y\]</span></p>
<p>Claramente, se todos os autovalores fossem substituídos pelo maior autovalor, nós teríamos um número maior (não esqueçam que <span class="math inline">\(y\Lambda{}y^{\prime} = \sum_{i=1}^{p} y_i^2\lambda_i\)</span>); se substituíssemos todos os autovalores pelo menor autovalor, teríamos um número menor. O maior e o menor autovalor limitam o valor possível de <span class="math inline">\(y \Lambda y^{\prime}\)</span>. Pra facilitar a vida, eu vou considerar os autovalores em ordem decrescente, então <span class="math inline">\(\lambda_1 &gt; \lambda_2 &gt; ... &gt;\lambda_p\)</span>:</p>
<p><span class="math display">\[y\lambda_1y^{\prime} &gt; y \Lambda y^{\prime} &gt; y \lambda_p y^{\prime}\]</span></p>
<p>Como <span class="math inline">\(\lambda_1\)</span> e <span class="math inline">\(\lambda_p\)</span> são escalares:</p>
<p><span class="math display">\[y^{\prime}\lambda_1y = \lambda_1 y^{\prime} y = \lambda_1 \omega^{\prime} P^{\prime} P \omega\]</span></p>
<p>Na última igualdade eu só substitui a definição de <span class="math inline">\(y\)</span>. Como <span class="math inline">\(P^{\prime} = P^{-1}\)</span>, temos:</p>
<p><span class="math display">\[\lambda_1 \omega^{\prime} P^{\prime} P \omega = \lambda_1 \omega^{\prime} \omega\]</span></p>
<p>Substituindo no problema original, temos:</p>
<p><span class="math display">\[\lambda_1 \omega^{\prime} \omega \geq \omega^{\prime} \Sigma \omega \geq \lambda_p \omega^{\prime}\omega\]</span></p>
<p>Agora, <span class="math inline">\(\omega^{\prime}\omega\)</span> é um escalar, então podemos dividir tudo por essa quantidade e obter:</p>
<p><span class="math display">\[\lambda_1 \geq \frac{\omega^{\prime}\Sigma \omega}{\omega^{\prime} \omega} \geq \lambda_p\]</span></p>
<p>Impondo a restrição de <span class="math inline">\(\omega^{\prime}\omega\)</span>, nós teremos que:</p>
<p><span class="math display">\[\lambda_1 \geq \omega^{\prime}\Sigma \omega\geq \lambda_p\]</span></p>
<p>Então a “maior variância possível” é representada pelo maior autovalor e o vetor que realiza a rotação é o autovetor associado.</p>
</div>
<div id="svd" class="section level2">
<h2>SVD</h2>
<p>A decomposição em valores singulares (<em>Singular Value Decomposition</em>) é outra decomposição bastante importante e famosa, mas nem sempre abordada em cursos de Álgebra Linear. Aplicando em uma matriz qualquer <span class="math inline">\(A\)</span>, que não precisa ser quadrada, o SVD faz:</p>
<p><span class="math display">\[A = USV^{\prime}\]</span></p>
<p>E <span class="math inline">\(U\)</span> e <span class="math inline">\(V\)</span> são matrizes ortogonais (<span class="math inline">\(U^{\prime} = U^{-1}\)</span> e <span class="math inline">\(V^{\prime} = V^{-1}\)</span>) e <span class="math inline">\(S\)</span> é uma matriz diagonal cujo valores são chamados de valores singulares.</p>
<p>Veja que se tivermos trabalhando com <span class="math inline">\(A^{\prime}A\)</span> - como por exemplo no caso da matriz de covariância <span class="math inline">\(X^{\prime}X\)</span>, então usando o SVD de <span class="math inline">\(A\)</span> nós podemos reescrever:</p>
<p><span class="math display">\[A^{\prime}A = (USV^{\prime})^{\prime}USV^{\prime} = VSU^{\prime}USV^{\prime} = VS^2V^{\prime}\]</span></p>
<p>Então veja que os autovalores de <span class="math inline">\(A^{\prime}A\)</span> são os quadrados dos valores singulares de A e os autovetores são <span class="math inline">\(V\)</span>. Uma relação similar vale para <span class="math inline">\(AA^{\prime}\)</span>.</p>
<p>Como a variância empírica dos dados é calculada com <span class="math inline">\(X^{\prime}X\)</span>, a gente sequer precisa se preocupar em calcular a matriz de variância covariância dos dados, basta passar o SVD na matriz de dados.</p>
<p>Só para dar um exemplo, vamos pegar o famoso <code>mtcars</code>:</p>
<pre class="r"><code>data(&quot;mtcars&quot;)

xx &lt;- cbind(mtcars$mpg,mtcars$cyl,mtcars$disp,mtcars$hp)</code></pre>
<p>Tirando os componentes principais:</p>
<pre class="r"><code>comp &lt;- prcomp(xx,scale=T,center=T)</code></pre>
<p>Vamos ver a matriz de rotação:</p>
<pre class="r"><code>comp$rotation</code></pre>
<pre><code>##             PC1         PC2        PC3          PC4
## [1,] -0.4963126  0.41505710 -0.7624369 -0.009557844
## [2,]  0.5126614 -0.08416586 -0.3698824 -0.770247652
## [3,]  0.5060829 -0.31928855 -0.5109886  0.617110666
## [4,]  0.4844917  0.84776090  0.1441097  0.160628854</code></pre>
<p>Agora vamos tirar o SVD da matriz e ver a matriz <span class="math inline">\(V\)</span> da decomposição. Não esqueça que eu preciso centrar e escalar<code>xx</code> (os dados) para ter variância 1 (o que eu vou fazer com o <code>scale</code>):</p>
<pre class="r"><code>x_sc &lt;- scale(xx)
svd_x &lt;- svd(x_sc)

svd_x$v</code></pre>
<pre><code>##            [,1]        [,2]       [,3]         [,4]
## [1,] -0.4963126  0.41505710 -0.7624369 -0.009557844
## [2,]  0.5126614 -0.08416586 -0.3698824 -0.770247652
## [3,]  0.5060829 -0.31928855 -0.5109886  0.617110666
## [4,]  0.4844917  0.84776090  0.1441097  0.160628854</code></pre>
<p>Veja que devido a representação do computador de um número real ser finita, as duas representações podiam diferir um pouquinho por erro numérico - isso não acontece justamente porque o <code>prcomp</code> usa svd!</p>
<p>A gente pode fazer a mesma decomposição a partir da matriz de correlação usando os autovalores:</p>
<pre class="r"><code>cov_mat &lt;- cor(xx)
eigs &lt;- eigen(cov_mat)

eigs$vectors</code></pre>
<pre><code>##            [,1]        [,2]       [,3]         [,4]
## [1,]  0.4963126  0.41505710  0.7624369 -0.009557844
## [2,] -0.5126614 -0.08416586  0.3698824 -0.770247652
## [3,] -0.5060829 -0.31928855  0.5109886  0.617110666
## [4,] -0.4844917  0.84776090 -0.1441097  0.160628854</code></pre>
<p>Veja que a diferença entre esses valores e a matriz v é que eles são multiplicados por -1</p>
<p>Muito conveniente quando a computação e a matemática concordam.</p>
</div>

                        </div><div class="tags my-3"><a class="badge badge-pill badge-light border mr-2" href="/tags/componentes-principais">
                                    <i class="fas fa-tag mr-2"></i>Componentes Principais
                                </a><a class="badge badge-pill badge-light border mr-2" href="/tags/%C3%A1lgebra-linear">
                                    <i class="fas fa-tag mr-2"></i>Álgebra Linear
                                </a><a class="badge badge-pill badge-light border mr-2" href="/tags/svd">
                                    <i class="fas fa-tag mr-2"></i>SVD
                                </a><a class="badge badge-pill badge-light border mr-2" href="/tags/autovalores">
                                    <i class="fas fa-tag mr-2"></i>Autovalores
                                </a></div><ul class="share nav my-3 justify-content-end">
        <li class="nav-item">
            <a class="nav-link" target="_blank" href="https://twitter.com/intent/tweet?url=%2f2020%2f09%2f07%2fcomponentes-principais-e-decomposi%25C3%25A7%25C3%25A3o-de-matrizes%2f&text=Componentes%20Principais%20e%20decomposi%c3%a7%c3%a3o%20de%20matrizes">
              <i class="fa-fw fab fa-twitter"></i>
          </a>
        </li>
        <li class="nav-item">
            <a class="nav-link" target="_blank" href="https://www.linkedin.com/shareArticle?url=%2f2020%2f09%2f07%2fcomponentes-principais-e-decomposi%25C3%25A7%25C3%25A3o-de-matrizes%2f&title=Componentes%20Principais%20e%20decomposi%c3%a7%c3%a3o%20de%20matrizes">
                <i class="fa-fw fab fa-linkedin-in"></i>
            </a>
        </li>
        <li class="nav-item">
            <a class="nav-link" target="_blank" href="https://www.facebook.com/sharer.php?u=%2f2020%2f09%2f07%2fcomponentes-principais-e-decomposi%25C3%25A7%25C3%25A3o-de-matrizes%2f&t=Componentes%20Principais%20e%20decomposi%c3%a7%c3%a3o%20de%20matrizes">
                <i class="fa-fw fab fa-facebook-f"></i>
            </a>
        </li>
        <li class="nav-item">
            <a class="nav-link" target="_blank" href="https://reddit.com/submit?url=%2f2020%2f09%2f07%2fcomponentes-principais-e-decomposi%25C3%25A7%25C3%25A3o-de-matrizes%2f&title=Componentes%20Principais%20e%20decomposi%c3%a7%c3%a3o%20de%20matrizes">
                <i class="fa-fw fab fa-reddit-alien"></i>
            </a>
        </li>
    </nav>
                    </div>
                </div>

                <div class="row justify-content-center">
                    <div class="col-lg-8">
                        
                    </div>
                </div></article>
        </div>
    </div>

    <div class="related-content row mt-5 row-cols-1 row-cols-lg-3"><div class="col mb-3">
                <div class="card h-100">
    
    <a href="/2018/11/06/sistemas-dinamicos-e-algebra-linear/" class="d-block"><div class="card-body">
            <h4 class="card-title">Sistemas Dinâmicos e Álgebra Linear</h4>
            <p class="card-text text-muted text-uppercase">November 6, 2018</p>
            <div class="card-text">
                Este é mais um post na linha de “como eu gostaria de ter sido apresentado à”. O tema de hoje é Algebra Linear. Este é um dos cursos que muitos alunos acham excessivamente abstrato, e portanto, inútil. De fato, eu tive um pouco desta sensação quando eu fiz o curso. A verdade está muito distante disso.
Suponha que nós temos um sistema de equações (lineares), e este sistema evolui ao longo do tempo.
            </div>
        </div>
    </a>
</div>

            </div><div class="col mb-3">
                <div class="card h-100">
    
    <a href="/2020/01/17/sistemas-din%C3%A2micos-ii/" class="d-block"><div class="card-body">
            <h4 class="card-title">Sistemas dinâmicos II: Expectativas racionais</h4>
            <p class="card-text text-muted text-uppercase">January 17, 2020</p>
            <div class="card-text">
                Há muito tempo atrás eu escrevi sobre Álgebra Linear e sistemas dinâmicos. Lá, eu falava de um caso em que o sistema era \(x_t = Ax_{t-1}\), onde \(x_t\) era um vetor e \(A\) tinha que ter autovalores menores que 1 em módulo para garantir a estabilidade do sistema. Apesar de ser um caso bem interessante, muitas vezes em economia nós temos que lidar com expectativas e assumimos expectativas racionais - que pode ser definida de várias maneiras, mas a mais intuitiva é pensar que agentes não cometem erros sistematicamente.
            </div>
        </div>
    </a>
</div>

            </div></div>
</main>


    <footer class="footer text-center bg-dark py-6">
    <div class="container">
        <div class="row">
            <div class="col">
                <ul class="list-inline">
                    <li class="list-inline-item"><a href="/index.xml" rel="alternate" type="application/rss+xml" class="icons d-block">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa fa-rss fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a></li><li class="list-inline-item">
                            <a href="https://github.com/danmrc/azul/tree/master/C%C3%B3digos" class="icons d-block">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                </ul>

                <p class="text-muted">
                    
                        Copyright © 2008–2020, Pedro Cavalcante & Daniel Coutinho; all rights reserved.
                    
                </p>

                <p class="text-muted">
                Powered by <a href="https://gohugo.io" target="_blank">Hugo</a> with <a href="https://github.com/puresyntax71/hugo-theme-chunky-poster" target="_blank">Chunky Poster</a>.
                </p>
            </div>
        </div>
    </div>
</footer>

    
    
        
            <script src="/dist/main.d608eadfe5ac0688902e.min.js"></script>
        
    






<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>

<script>
hljs.configure({languages: []});
hljs.initHighlightingOnLoad();
</script>


    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-123754589-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

</body>
</html>
