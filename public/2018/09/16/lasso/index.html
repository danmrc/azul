<!DOCTYPE html>
<html lang='en'>

<head>
  <meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'>
<meta name='description' content='Este post vai tratar de um método de machine learning muito interessante e relativamente simples: o LASSO. LASSO significa Least Absolute Shrinkage and Select Operator. Como o nome sugere, o LASSO seleciona quais regressores são relevantes e quais não são. Ou seja, suponha que você é um pesquisador que tem 50 variáveis que são possíveis candidatos a variáveis explicativas de uma variável de interesse. O LASSO permite que você dê os 50 regressores para o computador e ele escolha quais são os relevantes.'>
<meta name='theme-color' content='#ffcd00'>

<meta property='og:title' content='O LASSO • Daniel Coutinho'>
<meta property='og:description' content='Este post vai tratar de um método de machine learning muito interessante e relativamente simples: o LASSO. LASSO significa Least Absolute Shrinkage and Select Operator. Como o nome sugere, o LASSO seleciona quais regressores são relevantes e quais não são. Ou seja, suponha que você é um pesquisador que tem 50 variáveis que são possíveis candidatos a variáveis explicativas de uma variável de interesse. O LASSO permite que você dê os 50 regressores para o computador e ele escolha quais são os relevantes.'>
<meta property='og:url' content='/2018/09/16/lasso/'>
<meta property='og:site_name' content='AZUL'>
<meta property='og:type' content='article'><meta property='og:image' content='https://www.gravatar.com/avatar/1f9cf77b3ace375b20613f8985437059?s=256'><meta property='article:publisher' content='261817724519833'><meta property='article:section' content='post'><meta property='article:tag' content='LASSO'><meta property='article:tag' content='Machine Learning'><meta property='article:tag' content='R'><meta property='article:published_time' content='2018-09-16T00:00:00Z'/><meta property='article:modified_time' content='2018-09-16T00:00:00Z'/><meta property='fb:app_id' content='1762899530488891'><meta name='twitter:card' content='summary'>

<meta name="generator" content="Hugo 0.48" />

  <title>O LASSO • Daniel Coutinho</title>
  <link rel='canonical' href='/2018/09/16/lasso/'>
  
  
  <link rel='icon' href='/favicon.ico'>
<link rel='stylesheet' href='/assets/css/main.4267b3fa.css'><link rel='stylesheet' href='/css/custom.css'><style>
:root{--color-accent:#ffcd00;}
</style>

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-123754589-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

  

</head>


<body class='page type-post has-sidebar'>

  <div class='site'>

    <div id='sidebar' class='sidebar'>
  <a class='screen-reader-text' href='#main-menu'>Skip to Main Menu</a>

  <div class='container'><section class='widget widget-about sep-after'>
  <header>
    
    <div class='logo'>
      <a href='/'>
        <img src='/images/logo.png'>
      </a>
    </div>
    
    <h2 class='title site-title '>
    AZUL
    </h2>
    <div class='desc'>
    Economia, Estatística, Programação
    </div>
  </header>

</section>
<section class='widget widget-search sep-after'>
  <header>
    <h4 class='title widget-title'>Search</h4>
  </header>

  <form action='/search' id='search-form' class='search-form'>
    <label>
      <span class='screen-reader-text'>Search</span>
      <input id='search-term' class='search-term' type='search' name='q' placeholder='Search&hellip;'>
    </label></form>

</section>
<section class='widget widget-taxonomy_cloud sep-after'>
  <header>
    <h4 class='title widget-title'>Tags</h4>
  </header>

  <div class='container list-container'>
  <ul class='list taxonomy-cloud'><li>
        <a href='/tags/adf/' style='font-size:1em'>Adf</a>
      </li><li>
        <a href='/tags/an%C3%A1lise-de-sobreviv%C3%AAncia/' style='font-size:1em'>Análise De Sobrevivência</a>
      </li><li>
        <a href='/tags/apresenta%C3%A7%C3%A3o/' style='font-size:1em'>Apresentação</a>
      </li><li>
        <a href='/tags/autovalores/' style='font-size:1em'>Autovalores</a>
      </li><li>
        <a href='/tags/blanchard-quah/' style='font-size:1.0833333333333333em'>Blanchard Quah</a>
      </li><li>
        <a href='/tags/blogdown/' style='font-size:1em'>Blogdown</a>
      </li><li>
        <a href='/tags/bot/' style='font-size:1em'>Bot</a>
      </li><li>
        <a href='/tags/cadeias-de-markov/' style='font-size:1em'>Cadeias De Markov</a>
      </li><li>
        <a href='/tags/clustering/' style='font-size:1.0833333333333333em'>Clustering</a>
      </li><li>
        <a href='/tags/econometria/' style='font-size:1em'>Econometria</a>
      </li><li>
        <a href='/tags/economia/' style='font-size:1.1666666666666667em'>Economia</a>
      </li><li>
        <a href='/tags/economia-da-educa%C3%A7%C3%A3o/' style='font-size:1em'>Economia Da Educação</a>
      </li><li>
        <a href='/tags/instrumentos-fracos/' style='font-size:1em'>Instrumentos Fracos</a>
      </li><li>
        <a href='/tags/interpola%C3%A7%C3%A3o/' style='font-size:1em'>Interpolação</a>
      </li><li>
        <a href='/tags/julia/' style='font-size:1.4166666666666665em'>Julia</a>
      </li><li>
        <a href='/tags/lasso/' style='font-size:1em'>Lasso</a>
      </li><li>
        <a href='/tags/machine-learning/' style='font-size:1em'>Machine Learning</a>
      </li><li>
        <a href='/tags/macroeconomia/' style='font-size:1em'>Macroeconomia</a>
      </li><li>
        <a href='/tags/microeconomia/' style='font-size:1.1666666666666667em'>Microeconomia</a>
      </li><li>
        <a href='/tags/monte-carlo/' style='font-size:1.1666666666666667em'>Monte Carlo</a>
      </li><li>
        <a href='/tags/ponto-fixo/' style='font-size:1em'>Ponto Fixo</a>
      </li><li>
        <a href='/tags/price-puzzle/' style='font-size:1em'>Price Puzzle</a>
      </li><li>
        <a href='/tags/probit/' style='font-size:1em'>Probit</a>
      </li><li>
        <a href='/tags/profiling/' style='font-size:1em'>Profiling</a>
      </li><li>
        <a href='/tags/programa%C3%A7%C3%A3o-din%C3%A2mica/' style='font-size:1.25em'>Programação Dinâmica</a>
      </li><li>
        <a href='/tags/r/' style='font-size:2em'>R</a>
      </li><li>
        <a href='/tags/raiz-unit%C3%A1ria/' style='font-size:1em'>Raiz Unitária</a>
      </li><li>
        <a href='/tags/random-forest/' style='font-size:1em'>Random Forest</a>
      </li><li>
        <a href='/tags/replica%C3%A7%C3%A3o/' style='font-size:1em'>Replicação</a>
      </li><li>
        <a href='/tags/sazonalidade/' style='font-size:1em'>Sazonalidade</a>
      </li><li>
        <a href='/tags/simula%C3%A7%C3%A3o/' style='font-size:1.1666666666666667em'>Simulação</a>
      </li><li>
        <a href='/tags/sistemas-din%C3%A2micos/' style='font-size:1em'>Sistemas Dinâmicos</a>
      </li><li>
        <a href='/tags/solow/' style='font-size:1em'>Solow</a>
      </li><li>
        <a href='/tags/suaviza%C3%A7%C3%A3o-do-consumo/' style='font-size:1em'>Suavização Do Consumo</a>
      </li><li>
        <a href='/tags/svm/' style='font-size:1em'>Svm</a>
      </li><li>
        <a href='/tags/telegram/' style='font-size:1.0833333333333333em'>Telegram</a>
      </li><li>
        <a href='/tags/tutoriais/' style='font-size:1em'>Tutoriais</a>
      </li><li>
        <a href='/tags/var/' style='font-size:1em'>Var</a>
      </li><li>
        <a href='/tags/vari%C3%A1veis-instrumentais/' style='font-size:1.0833333333333333em'>Variáveis Instrumentais</a>
      </li><li>
        <a href='/tags/%C3%A1lgebra-linear/' style='font-size:1em'>Álgebra Linear</a>
      </li></ul>
</div>


</section>
</div>

  <div class='sidebar-overlay'></div>
</div>

    <div class='main'>

      <nav id='main-menu' class='menu main-menu' aria-label='Main Menu'>
  <div class='container'>
    <a class='screen-reader-text' href='#content'>Skip to Content</a>

<button id='sidebar-toggler' class='sidebar-toggler' aria-controls='sidebar'>
  <span class='screen-reader-text'>Toggle Sidebar</span>
  <span class='open'><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <line x1="3" y1="12" x2="21" y2="12" />
  <line x1="3" y1="6" x2="21" y2="6" />
  <line x1="3" y1="18" x2="21" y2="18" />
  
</svg>
</span>
  <span class='close'><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <line x1="18" y1="6" x2="6" y2="18" />
  <line x1="6" y1="6" x2="18" y2="18" />
  
</svg>
</span>
</button>
    <ul><li class='item'>
        <a href='https://github.com/danmrc/azul/tree/master/C%C3%B3digos'>GitHub</a>
      </li><li class='item'>
        <a href='/about/'>Sobre</a>
      </li><li class='item'>
        <a href='/post'>Tudo</a>
      </li><li class='item'>
        <a href=''>Twitter</a>
      </li></ul>
  </div>
</nav>

      <header id='header' class='header site-header'>
        <div class='container sep-after'>
          <div class='header-info'><p class='site-title title'>AZUL</p><p class='desc site-desc'>Economia, Estatística, Programação</p>
          </div>
        </div>
      </header>

      <main id='content'>


<article lang='en' class='entry'>
  <header class='header entry-header'>
  <div class='container sep-after'>
    <div class='header-info'>
      <h1 class='title'>O LASSO</h1>
      

    </div>
    
<div class='entry-meta'>
  <span class='posted-on'><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"/>
  <line x1="16" y1="2" x2="16" y2="6"/>
  <line x1="8" y1="2" x2="8" y2="6"/>
  <line x1="3" y1="10" x2="21" y2="10"/>
  
</svg>
<span class='screen-reader-text'>Posted on </span>
  <time class='entry-date' datetime='2018-09-16T00:00:00Z'>2018, Sep 16</time>
</span>

  <span class='byline'><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M21,21V20c0-2.76-4-5-9-5s-9,2.24-9,5v1"/>
  <path d="M16,6.37A4,4,0,1,1,12.63,3,4,4,0,0,1,16,6.37Z"/>
  
</svg>
<span class='screen-reader-text'> by </span><a href='/authors/danielc'>Daniel Coutinho</a></span>
  
<span class='reading-time'><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <circle cx="12" cy="12" r="10"/>
  <polyline points="12 6 12 12 15 15"/>
  
</svg>
9 mins read
</span>


</div>


  </div>
</header>

  
  

  <div class='container entry-content'>
  <p>Este post vai tratar de um método de machine learning muito interessante e relativamente simples: o LASSO. LASSO significa <em>Least Absolute Shrinkage and Select Operator</em>. Como o nome sugere, o LASSO <strong>seleciona quais regressores são relevantes e quais não são</strong>. Ou seja, suponha que você é um pesquisador que tem 50 variáveis que são possíveis candidatos a variáveis explicativas de uma variável de interesse. O LASSO permite que você dê os 50 regressores para o computador e ele escolha quais são os relevantes. O LASSO está centrado na ideia de <em>esparsidade</em>: poucos coeficientes vão ser diferentes de zero; poucas variáveis vão ser relevantes numa regressão.</p>
<p>Uma pergunta justa é: por que não simplesmente testamos isso “na mão”? Isso é, fazemos uma regressão com todas as variáveis, uma sem a primeira variável da base de dados, uma outra sem a segunda… e no fim vemos qual a melhor regressão? Além de problemas de teste - lembre que todo teste tem uma chance de você estar tomando a decisão <em>errada</em> - isso seria um inferno: com relés 50 variáveis, precisaríamos de <span class="math inline">\(2^{50}\)</span> regressões, ou seja, 1.125899910^{15} regressões: esse é um número com 15 zeros.</p>
<p>A ideia original vem de um paper de 1996 de Robert Tibshirani. Não temos solução fechada para encontrar o estimador de LASSO, ao contrário do MQO, onde podemos expressar o estimador como uma multiplicação de matrizes. Portanto, é um estimador que seria impossível sem um computador. Mas a ideia é incrivelmente simples.</p>
<p>Pegue o modelo usual de regressão, <span class="math inline">\(y_i = X_i \beta + u_i\)</span>, onde <span class="math inline">\(\beta\)</span> é o coeficiente de interesse, <span class="math inline">\(u\)</span> é um choque aleatório, as observações são indexadas por <span class="math inline">\(i = 1,...,n\)</span> e os coeficientes são indexados por <span class="math inline">\(k = 1,..,K\)</span> . O objetivo do MQO é minimizar a soma dos quadrados dos resíduos, ou seja <span class="math inline">\(\min_{\beta} \sum_{i=1}^n \hat{u}^2\)</span>. O LASSO começa dai, mas adiciona uma pequena alteração: vamos limitar o valor da soma dos valores absolutos dos coeficientes para que ele seja menor que uma constante <span class="math inline">\(c\)</span>. Ou seja, o LASSO resolve o problema:</p>
<p><span class="math display">\[\min_{\beta} \sum_{i=1}^n \hat{u}^2  \text{ sujeito a }  \sum_{k=1}^K |\beta_{k}| &lt; c\]</span></p>
<p>Veja que não temos como tirar a derivada da função módulo, e portanto não podemos resolver o problema “no braço”.</p>
<p>Podemos reescrever o problema como um la grangeano: <span class="math inline">\(\min_{\beta} \left( \sum_{i=1}^n \hat{u}^2 \right) - \lambda \left( \sum_{k=1}^K |\beta_{k}| \right)\)</span>, onde o <span class="math inline">\(\lambda\)</span> é o multiplicador de lagrange. Existe uma função que leva de <span class="math inline">\(c\)</span> para <span class="math inline">\(\lambda\)</span>, então podemos ignorar o valor de <span class="math inline">\(c\)</span> e pensar só em termos de <span class="math inline">\(\lambda\)</span>. Muitas implementações fazem isso e eu seguirei este caminho.</p>
<p>Veja que estamos trabalhando a soma do valor absoluto dos coeficientes. Chamamos isso de norma <span class="math inline">\(\ell_1\)</span>. Aqueles que já fizeram um curso de algebra linear conhecem a norma <span class="math inline">\(\ell_2\)</span>, conhecida como norma euclidiana: <span class="math inline">\(\sum_{k=1}^K \beta{}^2\)</span>. Existe um método de estimação que usa a norma <span class="math inline">\(\ell_2\)</span> ao invés da <span class="math inline">\(\ell_1\)</span>, conhecido como <em>ridge</em>. Usando a norma <span class="math inline">\(\ell_2\)</span>, o problema tem solução analítica. Então, por que norma <span class="math inline">\(\ell_1\)</span>, que parece ser tão ruim de trabalhar?</p>
<p>Esta é uma das belezas do LASSO: a norma <span class="math inline">\(\ell_2\)</span> <strong>não</strong> gera esparsidade. A norma <span class="math inline">\(\ell_1\)</span> gera. O motivo é ilustrado na figura abaixo, tirada de <em>Statistical Learning with Sparsity</em>, de Trevor Hastie, Robert Tibshirani and Martin Wainwright (cujo pdf, 100% legal, você encontra <a href="https://web.stanford.edu/~hastie/StatLearnSparsity_files/SLS_corrected_1.4.16.pdf">aqui</a>)</p>
<div class="figure">
<img src="/post/LASSO/aquela_classica_imagem_do_lasso.png" />

</div>
<p>A imagem supõe que você só tem duas variáveis, por motivos ilustrativos. O <span class="math inline">\(\hat{\beta}\)</span> é o máximo global, o conhecido estimador de MQO. Em vermelho são as curvas de nível do estimador. O que o <em>Ridge</em> (à direita) faz é impor uma restrição no formato de uma bola (azul). Veja que a curva de nível encosta na bola fora do eixo vertical - onde <span class="math inline">\(\beta_1\)</span> seria zero. Já o <em>LASSO</em> é ilustrado na figura à esquerda. Veja que, nesse caso, a curva de nível acerta na quina da restrição, efetivamente zerando o coeficiente <span class="math inline">\(\beta_1\)</span>.</p>
<p>Veja que, por enquanto, eu escondi o <span class="math inline">\(\lambda\)</span> (ou o <span class="math inline">\(c\)</span>) debaixo do tapete: eu ainda não expliquei como escolher essa variável, que de fato está no centro do problema. O pesquisador pode ter uma vaga ideia de quanto os coeficientes devem somar. Mas uma ideia exata do tamanho é complicada, então gostariamos de deixar os dados nos dizerem o <span class="math inline">\(\lambda\)</span> certo. Existem várias estratégias, e infelizmente o <code>glmnet</code> só implementa uma.</p>
<p>Com alguma ideia do que o LASSO está fazendo, podemos colocar a mão na massa e discutir o pacote padrão para o LASSO no R, o <code>glmnet</code>.</p>
<div id="o-pacote-glmnet" class="section level2">
<h2>O pacote glmnet</h2>
<p>Obviamente, começamos carregando o pacote:</p>
<pre class="r"><code>library(glmnet)</code></pre>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## Loading required package: foreach</code></pre>
<pre><code>## Loaded glmnet 2.0-16</code></pre>
<p>O comando para rodar uma regressão usando o LASSO é o <code>glmnet</code>. Ele recebe basicamente duas coisas, uma matriz com regressores e o vetor que é a variável dependente. Até ai, muito parecido com o MQO. Mas a grande diferença em termos de output é que o <code>glmnet</code> devolve uma <em>matriz</em> de coeficientes. O que o <code>glmnet</code> faz é estimar o modelo para um vetor de <span class="math inline">\(\lambda\)</span>, de tal forma que você vá de nenhuma variável incluida no modelo até todas as variáveis. Isso não significa que cada <span class="math inline">\(\lambda\)</span> estimado adicione uma variável nova ao modelo: em alguns casos o LASSO não seleciona mais ninguém, mas como ele tem mais “orçamento” para alocar, ele aumenta o valor dos coeficientes das variáveis incluídas. O <code>glmnet</code> resolve o problema de escolher qual <span class="math inline">\(\lambda\)</span> usar simplesmente estimando com vários valores diferentes.</p>
<p>Vamos testar o <code>glmnet</code> gerando uma matriz com 50 variáveis e 2000 observações e criando uma variável dependente que depende só das 10 primeiras variáveis:</p>
<pre class="r"><code>x &lt;- matrix(rnorm(2000*50), ncol = 50) #regressores
betas &lt;- c(rep(1,10),rep(0,40)) # as 10 primeiras serão relevantes com um coeficiente 1. As outras são irrelevantes - e portanto tem um coeficiente 0
y &lt;- x%*%betas + rnorm(2000) 

modelo &lt;- glmnet(x,y)
coef(modelo)[,1:5] # só pegando as 5 primeiras colunas. Veja que o comando summary não nos dá o que queremos no glmnet</code></pre>
<pre><code>## 51 x 5 sparse Matrix of class &quot;dgCMatrix&quot;
##                      s0           s1          s2          s3          s4
## (Intercept) -0.02236141 -0.024213986 -0.02408282 -0.02267777 -0.02158887
## V1           .           0.006876862  0.09575011  0.17453072  0.24630317
## V2           .           .            0.06824857  0.15461215  0.23346785
## V3           .           .            0.08042146  0.16019408  0.23296031
## V4           .           .            0.03010058  0.11588392  0.19410939
## V5           .           .            0.03868786  0.12617288  0.20601426
## V6           .           .            0.01207862  0.09721205  0.17469666
## V7           .           0.099490703  0.18116146  0.25477479  0.32192524
## V8           .           0.087586725  0.17083515  0.24721020  0.31704986
## V9           .           .            .           0.08388819  0.16614762
## V10          .           .            0.05542081  0.14004438  0.21702939
## V11          .           .            .           .           .         
## V12          .           .            .           .           .         
## V13          .           .            .           .           .         
## V14          .           .            .           .           .         
## V15          .           .            .           .           .         
## V16          .           .            .           .           .         
## V17          .           .            .           .           .         
## V18          .           .            .           .           .         
## V19          .           .            .           .           .         
## V20          .           .            .           .           .         
## V21          .           .            .           .           .         
## V22          .           .            .           .           .         
## V23          .           .            .           .           .         
## V24          .           .            .           .           .         
## V25          .           .            .           .           .         
## V26          .           .            .           .           .         
## V27          .           .            .           .           .         
## V28          .           .            .           .           .         
## V29          .           .            .           .           .         
## V30          .           .            .           .           .         
## V31          .           .            .           .           .         
## V32          .           .            .           .           .         
## V33          .           .            .           .           .         
## V34          .           .            .           .           .         
## V35          .           .            .           .           .         
## V36          .           .            .           .           .         
## V37          .           .            .           .           .         
## V38          .           .            .           .           .         
## V39          .           .            .           .           .         
## V40          .           .            .           .           .         
## V41          .           .            .           .           .         
## V42          .           .            .           .           .         
## V43          .           .            .           .           .         
## V44          .           .            .           .           .         
## V45          .           .            .           .           .         
## V46          .           .            .           .           .         
## V47          .           .            .           .           .         
## V48          .           .            .           .           .         
## V49          .           .            .           .           .         
## V50          .           .            .           .           .</code></pre>
<p>Obviamente, ainda temos que selecionar qual dos modelos nós queremos. O pacote nos permite selecionar por <em>Cross Validation</em> (CV). Em linhas gerais, o que o Cross Validation faz é separar os dados em <span class="math inline">\(k\)</span> blocos - 5,10, ou até mesmo blocos de uma única observação (conhecido como <em>leave one out</em>). Depois, escolha <span class="math inline">\(k-1\)</span> blocos e estime o modelo usando o <code>glmnet</code>. Para avaliar qual <span class="math inline">\(\lambda\)</span> devemos usar, use o bloco que <em>não</em> foi usado para estimar para ver qual modelo gera o menor erro segundo alguma métrica (erro quadrático médio, por exemplo). O CV vai permitir com que cada bloco tenha uma chance de ser “fora da amostra”.</p>
<p>Isso pode parecer muito computacionalmente intensivo - e de fato é - mas a implementação do glmnet é tão eficiente que normalmente num piscar de olhos o modelo é estimado - no meu Dell Vostro de 2012 com i5, 6GB e Windows 10, o tempo é de apenas 0.19s. O comando que faz a seleção do <span class="math inline">\(\lambda\)</span> é o <code>cv.glmnet</code>. Vamos testar no exemplo acima:</p>
<pre class="r"><code>cross_val &lt;- cv.glmnet(x,y)

coef(cross_val)</code></pre>
<pre><code>## 51 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                       1
## (Intercept) -0.01132651
## V1           0.92272709
## V2           0.97664814
## V3           0.91874905
## V4           0.93135112
## V5           0.95848594
## V6           0.90495909
## V7           0.95479111
## V8           0.97526108
## V9           0.94140976
## V10          0.94258243
## V11          .         
## V12          .         
## V13          .         
## V14          .         
## V15          .         
## V16          .         
## V17          .         
## V18          .         
## V19          .         
## V20          .         
## V21          .         
## V22          .         
## V23          .         
## V24          .         
## V25          .         
## V26          .         
## V27          .         
## V28          .         
## V29          .         
## V30          .         
## V31          .         
## V32          .         
## V33          .         
## V34          .         
## V35          .         
## V36          .         
## V37          .         
## V38          .         
## V39          .         
## V40          .         
## V41          .         
## V42          .         
## V43          .         
## V44          .         
## V45          .         
## V46          .         
## V47          .         
## V48          .         
## V49          .         
## V50          .</code></pre>
<p>O LASSO com CV põe apenas um coeficiente a mais. O <code>cv.glmnet</code> também fornece um plot com o número de coeficientes e o erro médio do Cross Validation, o que ajuda a ilustrar o ponto:</p>
<pre class="r"><code>plot(cross_val)</code></pre>
<p><img src="/post/LASSO/2018-09-01-LASSO_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Uma das linhas tracejadas marca o número de coeficientes escolhidos: 11, número em cima. Depois dessa linha tracejada, o <em>Mean Square Error</em> não flutua muito. E também não há muita variação para imediatamente a direita, onde temos o modelo verdadeiro com 10 coeficientes.</p>
<p><em>(O autor agradece aos Professores Marcelo Medeiros e Pedro Souza pelas longas explicações sobre o LASSO e métodos correlatos. Pedro Cava, o outro autor deste blog, foi primordial em incentivar esse texto. Todos os erros neste texto são, como de praxe, de minha exclusiva culpa)</em></p>
</div>

</div>

  
<footer class='entry-footer'>
  <div class='container sep-before'><div class='categories'><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M22,19a2,2,0,0,1-2,2H4a2,2,0,0,1-2-2V5A2,2,0,0,1,4,3H9l2,3h9a2,2,0,0,1,2,2Z"/>
  
</svg>
<span class='screen-reader-text'>Categories: </span></div>
<div class='tags'><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M20.59,13.41l-7.17,7.17a2,2,0,0,1-2.83,0L2,12V2H12l8.59,8.59A2,2,0,0,1,20.59,13.41Z"/>
  <line x1="7" y1="7" x2="7" y2="7"/>
  
</svg>
<span class='screen-reader-text'>Tags: </span></div>

  </div>
</footer>


</article>

<nav class='entry-nav'>
  <div class='container'><div class='prev-entry sep-before'>
      <a href='/2018/09/11/solow/'>
        <span aria-hidden='true'><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <line x1="20" y1="12" x2="4" y2="12"/>
  <polyline points="10 18 4 12 10 6"/>
  
</svg>
 Previous</span>
        <span class='screen-reader-text'>Previous post: </span>Explorando o Modelo de Solow com a ajuda do R</a>
    </div><div class='next-entry sep-before'>
      <a href='/2018/09/24/sazonalidade-x13-e-dummies-muito-barulho-por-nada/'>
        <span class='screen-reader-text'>Next post: </span>Sazonalidade, x13, e dummies: Muito barulho por nada<span aria-hidden='true'>Next <svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <line x1="4" y1="12" x2="20" y2="12"/>
  <polyline points="14 6 20 12 14 18"/>
  
</svg>
</span>
      </a>
    </div></div>
</nav>




      </main>

      <footer id='footer' class='footer'>
        <div class='container sep-before'><div class='copyright'>
  <p></p>
</div>

        </div>
      </footer>

    </div>
  </div><script>window.__public_path__='\/assets\/js\/'</script>

<script src='/assets/js/main.59f76c44.js'></script><script src='/js/custom.js'></script><link rel='stylesheet' href='//unpkg.com/katex/dist/katex.min.css'>
<script src='//unpkg.com/katex/dist/katex.min.js'></script>
<script src='//unpkg.com/katex/dist/contrib/auto-render.min.js'></script>

<script type='text/javascript'>
  renderMathInElement(document.querySelector('.entry-content'),{});
</script>

</body>

</html>

